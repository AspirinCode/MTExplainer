Changed directory to /home/dpk25/MolecularTransformer2/scripts/toy_model/sear_supBiased/convergence.

JobID: 27629469
======
Time: Wed 19 Aug 22:56:22 BST 2020
Running on master node: gpu-e-40
Current directory: /home/dpk25/MolecularTransformer2/scripts/toy_model/sear_supBiased/convergence

Nodes allocated:
================
gpu-e-40

numtasks=1, numnodes=1, mpi_tasks_per_node=1 (OMP_NUM_THREADS=1)

Executing command:
==================
./train.sh 

[2020-08-19 22:56:29,514 INFO]  * src vocab size = 18
[2020-08-19 22:56:29,514 INFO]  * tgt vocab size = 18
[2020-08-19 22:56:29,514 INFO] Building model...
[2020-08-19 22:56:36,078 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=18, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-19 22:56:36,080 INFO] encoder: 5265408
[2020-08-19 22:56:36,080 INFO] decoder: 6320146
[2020-08-19 22:56:36,080 INFO] * number of parameters: 11585554
[2020-08-19 22:56:36,084 INFO] Starting training on GPU: [0]
[2020-08-19 22:56:36,084 INFO] Start training loop and validate every 10000 steps...
[2020-08-19 22:56:36,084 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 22:56:36,155 INFO] number of examples: 4848
[2020-08-19 22:57:00,185 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_152.pt
[2020-08-19 22:57:23,953 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_304.pt
[2020-08-19 22:57:47,692 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_456.pt
[2020-08-19 22:57:49,333 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 22:57:49,383 INFO] number of examples: 4848
[2020-08-19 22:58:11,558 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_608.pt
[2020-08-19 22:58:35,360 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_760.pt
[2020-08-19 22:58:59,232 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_912.pt
[2020-08-19 22:59:02,007 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 22:59:02,026 INFO] number of examples: 4848
[2020-08-19 22:59:13,160 INFO] Step 1000/10000; acc:  80.64; ppl:  1.55; xent: 0.44; lr: 0.00140; 2547/2051 tok/s;    157 sec
[2020-08-19 22:59:23,016 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_1064.pt
[2020-08-19 22:59:46,754 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_1216.pt
[2020-08-19 23:00:11,337 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_1368.pt
[2020-08-19 23:00:15,364 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:00:15,406 INFO] number of examples: 4848
[2020-08-19 23:00:35,201 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_1520.pt
[2020-08-19 23:00:59,830 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_1672.pt
[2020-08-19 23:01:23,623 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_1824.pt
[2020-08-19 23:01:29,006 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:01:29,027 INFO] number of examples: 4848
[2020-08-19 23:01:47,447 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_1976.pt
[2020-08-19 23:01:51,469 INFO] Step 2000/10000; acc:  85.81; ppl:  1.35; xent: 0.30; lr: 0.00279; 2527/2035 tok/s;    315 sec
[2020-08-19 23:02:11,171 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_2128.pt
[2020-08-19 23:02:35,092 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_2280.pt
[2020-08-19 23:02:41,716 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:02:41,763 INFO] number of examples: 4848
[2020-08-19 23:02:58,982 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_2432.pt
[2020-08-19 23:03:23,498 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_2584.pt
[2020-08-19 23:03:47,562 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_2736.pt
[2020-08-19 23:03:55,594 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:03:55,616 INFO] number of examples: 4848
[2020-08-19 23:04:11,558 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_2888.pt
[2020-08-19 23:04:29,332 INFO] Step 3000/10000; acc:  87.17; ppl:  1.31; xent: 0.27; lr: 0.00228; 2538/2043 tok/s;    473 sec
[2020-08-19 23:04:35,479 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_3040.pt
[2020-08-19 23:04:59,221 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_3192.pt
[2020-08-19 23:05:08,349 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:05:08,399 INFO] number of examples: 4848
[2020-08-19 23:05:23,097 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_3344.pt
[2020-08-19 23:05:46,871 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_3496.pt
[2020-08-19 23:06:10,655 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_3648.pt
[2020-08-19 23:06:21,159 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:06:21,180 INFO] number of examples: 4848
[2020-08-19 23:06:34,468 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_3800.pt
[2020-08-19 23:06:58,125 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_3952.pt
[2020-08-19 23:07:05,947 INFO] Step 4000/10000; acc:  87.22; ppl:  1.31; xent: 0.27; lr: 0.00198; 2556/2058 tok/s;    630 sec
[2020-08-19 23:07:21,964 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_4104.pt
[2020-08-19 23:07:33,723 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:07:33,773 INFO] number of examples: 4848
[2020-08-19 23:07:45,783 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_4256.pt
[2020-08-19 23:08:09,432 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_4408.pt
[2020-08-19 23:08:33,183 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_4560.pt
[2020-08-19 23:08:46,158 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:08:46,181 INFO] number of examples: 4848
[2020-08-19 23:08:56,989 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_4712.pt
[2020-08-19 23:09:20,717 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_4864.pt
[2020-08-19 23:09:41,937 INFO] Step 5000/10000; acc:  87.36; ppl:  1.30; xent: 0.27; lr: 0.00177; 2562/2063 tok/s;    786 sec
[2020-08-19 23:09:44,393 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_5016.pt
[2020-08-19 23:09:59,291 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:09:59,311 INFO] number of examples: 4848
[2020-08-19 23:10:08,899 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_5168.pt
[2020-08-19 23:10:32,631 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_5320.pt
[2020-08-19 23:10:56,354 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_5472.pt
[2020-08-19 23:11:11,880 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:11:11,922 INFO] number of examples: 4848
[2020-08-19 23:11:20,135 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_5624.pt
[2020-08-19 23:11:43,829 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_5776.pt
[2020-08-19 23:12:07,590 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_5928.pt
[2020-08-19 23:12:19,084 INFO] Step 6000/10000; acc:  87.98; ppl:  1.28; xent: 0.25; lr: 0.00161; 2545/2049 tok/s;    943 sec
[2020-08-19 23:12:24,473 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:12:24,494 INFO] number of examples: 4848
[2020-08-19 23:12:31,472 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_6080.pt
[2020-08-19 23:12:55,221 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_6232.pt
[2020-08-19 23:13:18,896 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_6384.pt
[2020-08-19 23:13:37,046 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:13:37,092 INFO] number of examples: 4848
[2020-08-19 23:13:42,846 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_6536.pt
[2020-08-19 23:14:06,762 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_6688.pt
[2020-08-19 23:14:31,712 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_6840.pt
[2020-08-19 23:14:51,474 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:14:51,496 INFO] number of examples: 4848
[2020-08-19 23:14:56,099 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_6992.pt
[2020-08-19 23:14:57,737 INFO] Step 7000/10000; acc:  88.35; ppl:  1.27; xent: 0.24; lr: 0.00149; 2522/2031 tok/s;   1102 sec
[2020-08-19 23:15:20,358 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_7144.pt
[2020-08-19 23:15:44,633 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_7296.pt
[2020-08-19 23:16:05,728 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:16:05,775 INFO] number of examples: 4848
[2020-08-19 23:16:08,973 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_7448.pt
[2020-08-19 23:16:33,245 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_7600.pt
[2020-08-19 23:16:57,444 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_7752.pt
[2020-08-19 23:17:19,834 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:17:19,856 INFO] number of examples: 4848
[2020-08-19 23:17:21,777 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_7904.pt
[2020-08-19 23:17:37,274 INFO] Step 8000/10000; acc:  88.74; ppl:  1.25; xent: 0.23; lr: 0.00140; 2508/2020 tok/s;   1261 sec
[2020-08-19 23:17:46,080 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_8056.pt
[2020-08-19 23:18:10,512 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_8208.pt
[2020-08-19 23:18:34,161 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:18:34,210 INFO] number of examples: 4848
[2020-08-19 23:18:34,872 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_8360.pt
[2020-08-19 23:18:59,283 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_8512.pt
[2020-08-19 23:19:23,528 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_8664.pt
[2020-08-19 23:19:47,915 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_8816.pt
[2020-08-19 23:19:48,820 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:19:48,841 INFO] number of examples: 4848
[2020-08-19 23:20:12,180 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_8968.pt
[2020-08-19 23:20:17,530 INFO] Step 9000/10000; acc:  88.62; ppl:  1.26; xent: 0.23; lr: 0.00132; 2498/2010 tok/s;   1421 sec
[2020-08-19 23:20:36,426 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_9120.pt
[2020-08-19 23:21:00,718 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_9272.pt
[2020-08-19 23:21:03,238 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:21:03,289 INFO] number of examples: 4848
[2020-08-19 23:21:25,247 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_9424.pt
[2020-08-19 23:21:49,413 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_9576.pt
[2020-08-19 23:22:13,713 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_9728.pt
[2020-08-19 23:22:17,292 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:22:17,321 INFO] number of examples: 4848
[2020-08-19 23:22:38,006 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_9880.pt
[2020-08-19 23:22:57,226 INFO] Step 10000/10000; acc:  89.36; ppl:  1.23; xent: 0.21; lr: 0.00125; 2509/2020 tok/s;   1581 sec
[2020-08-19 23:22:57,227 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.valid.0.pt
[2020-08-19 23:22:57,260 INFO] number of examples: 303
[2020-08-19 23:22:57,783 INFO] Validation perplexity: 1.25629
[2020-08-19 23:22:57,783 INFO] Validation accuracy: 91.0924
[2020-08-19 23:22:57,785 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv1/toy_model_step_10000.pt
[2020-08-19 23:23:00,388 INFO]  * src vocab size = 18
[2020-08-19 23:23:00,388 INFO]  * tgt vocab size = 18
[2020-08-19 23:23:00,389 INFO] Building model...
[2020-08-19 23:23:02,525 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=18, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-19 23:23:02,528 INFO] encoder: 5265408
[2020-08-19 23:23:02,528 INFO] decoder: 6320146
[2020-08-19 23:23:02,528 INFO] * number of parameters: 11585554
[2020-08-19 23:23:02,536 INFO] Starting training on GPU: [0]
[2020-08-19 23:23:02,537 INFO] Start training loop and validate every 10000 steps...
[2020-08-19 23:23:02,537 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:23:02,566 INFO] number of examples: 4848
[2020-08-19 23:23:26,583 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_152.pt
[2020-08-19 23:23:50,733 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_304.pt
[2020-08-19 23:24:14,820 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_456.pt
[2020-08-19 23:24:16,417 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:24:16,466 INFO] number of examples: 4848
[2020-08-19 23:24:39,036 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_608.pt
[2020-08-19 23:25:03,170 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_760.pt
[2020-08-19 23:25:27,464 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_912.pt
[2020-08-19 23:25:30,271 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:25:30,291 INFO] number of examples: 4848
[2020-08-19 23:25:41,591 INFO] Step 1000/10000; acc:  80.25; ppl:  1.58; xent: 0.45; lr: 0.00140; 2516/2026 tok/s;    159 sec
[2020-08-19 23:25:51,600 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_1064.pt
[2020-08-19 23:26:15,820 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_1216.pt
[2020-08-19 23:26:39,985 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_1368.pt
[2020-08-19 23:26:44,009 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:26:44,055 INFO] number of examples: 4848
[2020-08-19 23:27:04,105 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_1520.pt
[2020-08-19 23:27:30,768 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_1672.pt
[2020-08-19 23:27:54,788 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_1824.pt
[2020-08-19 23:28:00,272 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:28:00,293 INFO] number of examples: 4848
[2020-08-19 23:28:18,964 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_1976.pt
[2020-08-19 23:28:23,025 INFO] Step 2000/10000; acc:  85.90; ppl:  1.35; xent: 0.30; lr: 0.00279; 2479/1996 tok/s;    320 sec
[2020-08-19 23:28:43,110 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_2128.pt
[2020-08-19 23:29:07,470 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_2280.pt
[2020-08-19 23:29:14,251 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:29:14,298 INFO] number of examples: 4848
[2020-08-19 23:29:31,679 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_2432.pt
[2020-08-19 23:29:55,853 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_2584.pt
[2020-08-19 23:30:19,970 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_2736.pt
[2020-08-19 23:30:27,979 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:30:28,000 INFO] number of examples: 4848
[2020-08-19 23:30:44,138 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_2888.pt
[2020-08-19 23:31:01,982 INFO] Step 3000/10000; acc:  86.06; ppl:  1.34; xent: 0.30; lr: 0.00228; 2517/2027 tok/s;    479 sec
[2020-08-19 23:31:08,245 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_3040.pt
[2020-08-19 23:31:32,352 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_3192.pt
[2020-08-19 23:31:41,650 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:31:41,701 INFO] number of examples: 4848
[2020-08-19 23:31:56,597 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_3344.pt
[2020-08-19 23:32:20,738 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_3496.pt
[2020-08-19 23:32:44,903 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_3648.pt
[2020-08-19 23:32:55,537 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:32:55,559 INFO] number of examples: 4848
[2020-08-19 23:33:08,995 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_3800.pt
[2020-08-19 23:33:33,175 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_3952.pt
[2020-08-19 23:33:41,038 INFO] Step 4000/10000; acc:  87.23; ppl:  1.30; xent: 0.26; lr: 0.00198; 2514/2025 tok/s;    639 sec
[2020-08-19 23:33:57,321 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_4104.pt
[2020-08-19 23:34:09,240 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:34:09,262 INFO] number of examples: 4848
[2020-08-19 23:34:21,529 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_4256.pt
[2020-08-19 23:34:45,652 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_4408.pt
[2020-08-19 23:35:09,768 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_4560.pt
[2020-08-19 23:35:22,990 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:35:23,047 INFO] number of examples: 4848
[2020-08-19 23:35:34,027 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_4712.pt
[2020-08-19 23:35:58,230 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_4864.pt
[2020-08-19 23:36:20,305 INFO] Step 5000/10000; acc:  87.58; ppl:  1.29; xent: 0.25; lr: 0.00177; 2513/2022 tok/s;    798 sec
[2020-08-19 23:36:22,813 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_5016.pt
[2020-08-19 23:36:37,235 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:36:37,257 INFO] number of examples: 4848
[2020-08-19 23:36:47,008 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_5168.pt
[2020-08-19 23:37:11,104 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_5320.pt
[2020-08-19 23:37:35,218 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_5472.pt
[2020-08-19 23:37:51,044 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:37:51,088 INFO] number of examples: 4848
[2020-08-19 23:37:59,424 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_5624.pt
[2020-08-19 23:38:23,445 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_5776.pt
[2020-08-19 23:38:47,459 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_5928.pt
[2020-08-19 23:38:59,007 INFO] Step 6000/10000; acc:  87.35; ppl:  1.30; xent: 0.26; lr: 0.00161; 2523/2032 tok/s;    956 sec
[2020-08-19 23:39:04,437 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:39:04,458 INFO] number of examples: 4848
[2020-08-19 23:39:11,468 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_6080.pt
[2020-08-19 23:39:35,321 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_6232.pt
[2020-08-19 23:39:58,968 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_6384.pt
[2020-08-19 23:40:17,005 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:40:17,049 INFO] number of examples: 4848
[2020-08-19 23:40:22,759 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_6536.pt
[2020-08-19 23:40:46,525 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_6688.pt
[2020-08-19 23:41:10,192 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_6840.pt
[2020-08-19 23:41:29,420 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:41:29,443 INFO] number of examples: 4848
[2020-08-19 23:41:33,935 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_6992.pt
[2020-08-19 23:41:35,489 INFO] Step 7000/10000; acc:  88.04; ppl:  1.27; xent: 0.24; lr: 0.00149; 2556/2058 tok/s;   1113 sec
[2020-08-19 23:41:57,614 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_7144.pt
[2020-08-19 23:42:21,355 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_7296.pt
[2020-08-19 23:42:42,003 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:42:42,051 INFO] number of examples: 4848
[2020-08-19 23:42:45,174 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_7448.pt
[2020-08-19 23:43:08,830 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_7600.pt
[2020-08-19 23:43:32,694 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_7752.pt
[2020-08-19 23:43:54,594 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:43:54,615 INFO] number of examples: 4848
[2020-08-19 23:43:56,493 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_7904.pt
[2020-08-19 23:44:11,701 INFO] Step 8000/10000; acc:  88.52; ppl:  1.26; xent: 0.23; lr: 0.00140; 2563/2063 tok/s;   1269 sec
[2020-08-19 23:44:20,326 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_8056.pt
[2020-08-19 23:44:43,997 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_8208.pt
[2020-08-19 23:45:07,070 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:45:07,118 INFO] number of examples: 4848
[2020-08-19 23:45:07,769 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_8360.pt
[2020-08-19 23:45:31,404 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_8512.pt
[2020-08-19 23:45:55,084 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_8664.pt
[2020-08-19 23:46:18,843 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_8816.pt
[2020-08-19 23:46:19,723 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:46:19,744 INFO] number of examples: 4848
[2020-08-19 23:46:42,493 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_8968.pt
[2020-08-19 23:46:47,693 INFO] Step 9000/10000; acc:  87.63; ppl:  1.29; xent: 0.25; lr: 0.00132; 2565/2065 tok/s;   1425 sec
[2020-08-19 23:47:06,124 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_9120.pt
[2020-08-19 23:47:29,882 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_9272.pt
[2020-08-19 23:47:32,164 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:47:32,211 INFO] number of examples: 4848
[2020-08-19 23:47:53,603 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_9424.pt
[2020-08-19 23:48:17,311 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_9576.pt
[2020-08-19 23:48:40,961 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_9728.pt
[2020-08-19 23:48:44,472 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:48:44,494 INFO] number of examples: 4848
[2020-08-19 23:49:04,600 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_9880.pt
[2020-08-19 23:49:23,308 INFO] Step 10000/10000; acc:  88.75; ppl:  1.25; xent: 0.22; lr: 0.00125; 2571/2070 tok/s;   1581 sec
[2020-08-19 23:49:23,309 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.valid.0.pt
[2020-08-19 23:49:23,356 INFO] number of examples: 303
[2020-08-19 23:49:23,889 INFO] Validation perplexity: 1.26572
[2020-08-19 23:49:23,889 INFO] Validation accuracy: 90.9964
[2020-08-19 23:49:23,891 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv2/toy_model_step_10000.pt
[2020-08-19 23:49:25,268 INFO]  * src vocab size = 18
[2020-08-19 23:49:25,269 INFO]  * tgt vocab size = 18
[2020-08-19 23:49:25,269 INFO] Building model...
[2020-08-19 23:49:27,409 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=18, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-19 23:49:27,411 INFO] encoder: 5265408
[2020-08-19 23:49:27,411 INFO] decoder: 6320146
[2020-08-19 23:49:27,412 INFO] * number of parameters: 11585554
[2020-08-19 23:49:27,415 INFO] Starting training on GPU: [0]
[2020-08-19 23:49:27,415 INFO] Start training loop and validate every 10000 steps...
[2020-08-19 23:49:27,415 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:49:27,439 INFO] number of examples: 4848
[2020-08-19 23:49:50,953 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_152.pt
[2020-08-19 23:50:14,659 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_304.pt
[2020-08-19 23:50:38,275 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_456.pt
[2020-08-19 23:50:39,846 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:50:39,894 INFO] number of examples: 4848
[2020-08-19 23:51:02,034 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_608.pt
[2020-08-19 23:51:25,735 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_760.pt
[2020-08-19 23:51:49,351 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_912.pt
[2020-08-19 23:51:52,112 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:51:52,132 INFO] number of examples: 4848
[2020-08-19 23:52:03,196 INFO] Step 1000/10000; acc:  80.26; ppl:  1.57; xent: 0.45; lr: 0.00140; 2568/2067 tok/s;    156 sec
[2020-08-19 23:52:13,026 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_1064.pt
[2020-08-19 23:52:36,731 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_1216.pt
[2020-08-19 23:53:00,325 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_1368.pt
[2020-08-19 23:53:04,388 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:53:04,435 INFO] number of examples: 4848
[2020-08-19 23:53:24,149 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_1520.pt
[2020-08-19 23:53:47,797 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_1672.pt
[2020-08-19 23:54:11,460 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_1824.pt
[2020-08-19 23:54:17,034 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:54:17,056 INFO] number of examples: 4848
[2020-08-19 23:54:35,363 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_1976.pt
[2020-08-19 23:54:39,417 INFO] Step 2000/10000; acc:  85.90; ppl:  1.35; xent: 0.30; lr: 0.00279; 2563/2063 tok/s;    312 sec
[2020-08-19 23:54:59,116 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_2128.pt
[2020-08-19 23:55:22,833 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_2280.pt
[2020-08-19 23:55:29,385 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:55:29,435 INFO] number of examples: 4848
[2020-08-19 23:55:46,476 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_2432.pt
[2020-08-19 23:56:10,212 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_2584.pt
[2020-08-19 23:56:34,001 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_2736.pt
[2020-08-19 23:56:41,898 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:56:41,923 INFO] number of examples: 4848
[2020-08-19 23:56:57,757 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_2888.pt
[2020-08-19 23:57:15,222 INFO] Step 3000/10000; acc:  86.44; ppl:  1.33; xent: 0.28; lr: 0.00228; 2565/2065 tok/s;    468 sec
[2020-08-19 23:57:21,403 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_3040.pt
[2020-08-19 23:57:45,094 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_3192.pt
[2020-08-19 23:57:54,198 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:57:54,248 INFO] number of examples: 4848
[2020-08-19 23:58:08,871 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_3344.pt
[2020-08-19 23:58:32,515 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_3496.pt
[2020-08-19 23:58:56,160 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_3648.pt
[2020-08-19 23:59:06,593 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-19 23:59:06,615 INFO] number of examples: 4848
[2020-08-19 23:59:19,830 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_3800.pt
[2020-08-19 23:59:43,534 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_3952.pt
[2020-08-19 23:59:51,228 INFO] Step 4000/10000; acc:  86.64; ppl:  1.32; xent: 0.28; lr: 0.00198; 2565/2066 tok/s;    624 sec
[2020-08-20 00:00:07,220 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_4104.pt
[2020-08-20 00:00:18,940 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:00:18,962 INFO] number of examples: 4848
[2020-08-20 00:00:30,996 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_4256.pt
[2020-08-20 00:00:54,669 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_4408.pt
[2020-08-20 00:01:18,471 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_4560.pt
[2020-08-20 00:01:31,414 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:01:31,435 INFO] number of examples: 4848
[2020-08-20 00:01:42,230 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_4712.pt
[2020-08-20 00:02:05,895 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_4864.pt
[2020-08-20 00:02:27,179 INFO] Step 5000/10000; acc:  87.63; ppl:  1.28; xent: 0.25; lr: 0.00177; 2566/2066 tok/s;    780 sec
[2020-08-20 00:02:29,639 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_5016.pt
[2020-08-20 00:02:43,785 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:02:43,807 INFO] number of examples: 4848
[2020-08-20 00:02:53,373 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_5168.pt
[2020-08-20 00:03:17,069 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_5320.pt
[2020-08-20 00:03:40,801 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_5472.pt
[2020-08-20 00:03:56,295 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:03:56,341 INFO] number of examples: 4848
[2020-08-20 00:04:04,512 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_5624.pt
[2020-08-20 00:04:28,230 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_5776.pt
[2020-08-20 00:04:51,886 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_5928.pt
[2020-08-20 00:05:03,333 INFO] Step 6000/10000; acc:  87.35; ppl:  1.30; xent: 0.26; lr: 0.00161; 2563/2063 tok/s;    936 sec
[2020-08-20 00:05:08,736 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:05:08,757 INFO] number of examples: 4848
[2020-08-20 00:05:15,697 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_6080.pt
[2020-08-20 00:05:39,623 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_6232.pt
[2020-08-20 00:06:03,248 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_6384.pt
[2020-08-20 00:06:21,279 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:06:21,324 INFO] number of examples: 4848
[2020-08-20 00:06:27,028 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_6536.pt
[2020-08-20 00:06:50,639 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_6688.pt
[2020-08-20 00:07:14,378 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_6840.pt
[2020-08-20 00:07:33,641 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:07:33,663 INFO] number of examples: 4848
[2020-08-20 00:07:38,139 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_6992.pt
[2020-08-20 00:07:39,649 INFO] Step 7000/10000; acc:  87.80; ppl:  1.28; xent: 0.24; lr: 0.00149; 2562/2063 tok/s;   1092 sec
[2020-08-20 00:08:01,751 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_7144.pt
[2020-08-20 00:08:25,494 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_7296.pt
[2020-08-20 00:08:46,131 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:08:46,177 INFO] number of examples: 4848
[2020-08-20 00:08:49,274 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_7448.pt
[2020-08-20 00:09:12,912 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_7600.pt
[2020-08-20 00:09:36,666 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_7752.pt
[2020-08-20 00:09:58,488 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:09:58,510 INFO] number of examples: 4848
[2020-08-20 00:10:00,390 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_7904.pt
[2020-08-20 00:10:15,452 INFO] Step 8000/10000; acc:  87.62; ppl:  1.28; xent: 0.24; lr: 0.00140; 2567/2067 tok/s;   1248 sec
[2020-08-20 00:10:24,069 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_8056.pt
[2020-08-20 00:10:47,792 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_8208.pt
[2020-08-20 00:11:10,831 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:11:10,878 INFO] number of examples: 4848
[2020-08-20 00:11:11,528 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_8360.pt
[2020-08-20 00:11:35,187 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_8512.pt
[2020-08-20 00:11:58,958 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_8664.pt
[2020-08-20 00:12:22,626 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_8816.pt
[2020-08-20 00:12:23,514 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:12:23,542 INFO] number of examples: 4848
[2020-08-20 00:12:46,330 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_8968.pt
[2020-08-20 00:12:51,553 INFO] Step 9000/10000; acc:  87.56; ppl:  1.28; xent: 0.25; lr: 0.00132; 2564/2063 tok/s;   1404 sec
[2020-08-20 00:13:10,008 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_9120.pt
[2020-08-20 00:13:33,770 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_9272.pt
[2020-08-20 00:13:36,056 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:13:36,105 INFO] number of examples: 4848
[2020-08-20 00:13:57,493 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_9424.pt
[2020-08-20 00:14:21,263 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_9576.pt
[2020-08-20 00:14:44,805 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_9728.pt
[2020-08-20 00:14:48,390 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:14:48,411 INFO] number of examples: 4848
[2020-08-20 00:15:08,403 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_9880.pt
[2020-08-20 00:15:27,014 INFO] Step 10000/10000; acc:  87.98; ppl:  1.26; xent: 0.23; lr: 0.00125; 2573/2071 tok/s;   1560 sec
[2020-08-20 00:15:27,015 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.valid.0.pt
[2020-08-20 00:15:27,024 INFO] number of examples: 303
[2020-08-20 00:15:27,543 INFO] Validation perplexity: 1.30255
[2020-08-20 00:15:27,543 INFO] Validation accuracy: 89.3429
[2020-08-20 00:15:27,544 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv3/toy_model_step_10000.pt
[2020-08-20 00:15:29,390 INFO]  * src vocab size = 18
[2020-08-20 00:15:29,390 INFO]  * tgt vocab size = 18
[2020-08-20 00:15:29,390 INFO] Building model...
[2020-08-20 00:15:31,520 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=18, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 00:15:31,523 INFO] encoder: 5265408
[2020-08-20 00:15:31,523 INFO] decoder: 6320146
[2020-08-20 00:15:31,523 INFO] * number of parameters: 11585554
[2020-08-20 00:15:31,526 INFO] Starting training on GPU: [0]
[2020-08-20 00:15:31,526 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 00:15:31,526 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:15:31,550 INFO] number of examples: 4848
[2020-08-20 00:15:55,660 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_152.pt
[2020-08-20 00:16:19,851 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_304.pt
[2020-08-20 00:16:44,026 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_456.pt
[2020-08-20 00:16:45,643 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:16:45,692 INFO] number of examples: 4848
[2020-08-20 00:17:08,291 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_608.pt
[2020-08-20 00:17:32,442 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_760.pt
[2020-08-20 00:17:56,596 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_912.pt
[2020-08-20 00:17:59,494 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:17:59,516 INFO] number of examples: 4848
[2020-08-20 00:18:10,855 INFO] Step 1000/10000; acc:  80.09; ppl:  1.57; xent: 0.45; lr: 0.00140; 2513/2023 tok/s;    159 sec
[2020-08-20 00:18:20,894 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_1064.pt
[2020-08-20 00:18:45,013 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_1216.pt
[2020-08-20 00:19:09,175 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_1368.pt
[2020-08-20 00:19:13,296 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:19:13,388 INFO] number of examples: 4848
[2020-08-20 00:19:33,514 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_1520.pt
[2020-08-20 00:19:57,661 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_1672.pt
[2020-08-20 00:20:21,829 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_1824.pt
[2020-08-20 00:20:28,185 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:20:28,206 INFO] number of examples: 4848
[2020-08-20 00:20:46,885 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_1976.pt
[2020-08-20 00:20:50,910 INFO] Step 2000/10000; acc:  85.41; ppl:  1.36; xent: 0.31; lr: 0.00279; 2501/2014 tok/s;    319 sec
[2020-08-20 00:21:11,034 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_2128.pt
[2020-08-20 00:21:35,270 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_2280.pt
[2020-08-20 00:21:42,197 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:21:42,244 INFO] number of examples: 4848
[2020-08-20 00:21:59,680 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_2432.pt
[2020-08-20 00:22:23,986 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_2584.pt
[2020-08-20 00:22:48,240 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_2736.pt
[2020-08-20 00:22:56,258 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:22:56,280 INFO] number of examples: 4848
[2020-08-20 00:23:12,501 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_2888.pt
[2020-08-20 00:23:30,527 INFO] Step 3000/10000; acc:  85.38; ppl:  1.36; xent: 0.31; lr: 0.00228; 2507/2018 tok/s;    479 sec
[2020-08-20 00:23:36,815 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_3040.pt
[2020-08-20 00:24:01,058 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_3192.pt
[2020-08-20 00:24:10,522 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:24:10,572 INFO] number of examples: 4848
[2020-08-20 00:24:25,545 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_3344.pt
[2020-08-20 00:24:50,085 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_3496.pt
[2020-08-20 00:25:14,329 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_3648.pt
[2020-08-20 00:25:25,046 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:25:25,084 INFO] number of examples: 4848
[2020-08-20 00:25:38,610 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_3800.pt
[2020-08-20 00:26:02,823 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_3952.pt
[2020-08-20 00:26:10,816 INFO] Step 4000/10000; acc:  87.02; ppl:  1.31; xent: 0.27; lr: 0.00198; 2495/2009 tok/s;    639 sec
[2020-08-20 00:26:27,178 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_4104.pt
[2020-08-20 00:26:39,056 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:26:39,078 INFO] number of examples: 4848
[2020-08-20 00:26:51,399 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_4256.pt
[2020-08-20 00:27:15,761 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_4408.pt
[2020-08-20 00:27:40,052 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_4560.pt
[2020-08-20 00:27:53,314 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:27:53,335 INFO] number of examples: 4848
[2020-08-20 00:28:04,385 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_4712.pt
[2020-08-20 00:28:28,695 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_4864.pt
[2020-08-20 00:28:50,567 INFO] Step 5000/10000; acc:  86.58; ppl:  1.32; xent: 0.28; lr: 0.00177; 2505/2017 tok/s;    799 sec
[2020-08-20 00:28:53,070 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_5016.pt
[2020-08-20 00:29:07,471 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:29:07,492 INFO] number of examples: 4848
[2020-08-20 00:29:17,161 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_5168.pt
[2020-08-20 00:29:41,045 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_5320.pt
[2020-08-20 00:30:04,937 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_5472.pt
[2020-08-20 00:30:20,562 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:30:20,606 INFO] number of examples: 4848
[2020-08-20 00:30:28,828 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_5624.pt
[2020-08-20 00:30:52,443 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_5776.pt
[2020-08-20 00:31:17,692 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_5928.pt
[2020-08-20 00:31:29,159 INFO] Step 6000/10000; acc:  87.99; ppl:  1.28; xent: 0.25; lr: 0.00161; 2522/2030 tok/s;    958 sec
[2020-08-20 00:31:34,568 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:31:34,589 INFO] number of examples: 4848
[2020-08-20 00:31:41,598 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_6080.pt
[2020-08-20 00:32:05,467 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_6232.pt
[2020-08-20 00:32:29,354 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_6384.pt
[2020-08-20 00:32:47,412 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:32:47,456 INFO] number of examples: 4848
[2020-08-20 00:32:53,169 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_6536.pt
[2020-08-20 00:33:17,042 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_6688.pt
[2020-08-20 00:33:40,886 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_6840.pt
[2020-08-20 00:34:00,190 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:34:00,214 INFO] number of examples: 4848
[2020-08-20 00:34:04,736 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_6992.pt
[2020-08-20 00:34:06,312 INFO] Step 7000/10000; acc:  88.59; ppl:  1.26; xent: 0.23; lr: 0.00149; 2547/2051 tok/s;   1115 sec
[2020-08-20 00:34:28,617 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_7144.pt
[2020-08-20 00:34:52,483 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_7296.pt
[2020-08-20 00:35:13,292 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:35:13,346 INFO] number of examples: 4848
[2020-08-20 00:35:16,473 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_7448.pt
[2020-08-20 00:35:40,371 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_7600.pt
[2020-08-20 00:36:04,226 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_7752.pt
[2020-08-20 00:36:26,781 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:36:26,802 INFO] number of examples: 4848
[2020-08-20 00:36:28,690 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_7904.pt
[2020-08-20 00:36:43,818 INFO] Step 8000/10000; acc:  88.67; ppl:  1.26; xent: 0.23; lr: 0.00140; 2542/2047 tok/s;   1272 sec
[2020-08-20 00:36:52,488 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_8056.pt
[2020-08-20 00:37:16,294 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_8208.pt
[2020-08-20 00:37:40,328 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:37:40,376 INFO] number of examples: 4848
[2020-08-20 00:37:41,029 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_8360.pt
[2020-08-20 00:38:04,992 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_8512.pt
[2020-08-20 00:38:28,815 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_8664.pt
[2020-08-20 00:38:52,651 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_8816.pt
[2020-08-20 00:38:53,631 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:38:53,651 INFO] number of examples: 4848
[2020-08-20 00:39:16,599 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_8968.pt
[2020-08-20 00:39:21,892 INFO] Step 9000/10000; acc:  88.80; ppl:  1.25; xent: 0.22; lr: 0.00132; 2532/2039 tok/s;   1430 sec
[2020-08-20 00:39:40,492 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_9120.pt
[2020-08-20 00:40:04,414 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_9272.pt
[2020-08-20 00:40:06,725 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:40:06,774 INFO] number of examples: 4848
[2020-08-20 00:40:28,299 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_9424.pt
[2020-08-20 00:40:52,092 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_9576.pt
[2020-08-20 00:41:15,784 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_9728.pt
[2020-08-20 00:41:19,325 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:41:19,347 INFO] number of examples: 4848
[2020-08-20 00:41:39,436 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_9880.pt
[2020-08-20 00:41:58,189 INFO] Step 10000/10000; acc:  88.89; ppl:  1.25; xent: 0.22; lr: 0.00125; 2561/2062 tok/s;   1587 sec
[2020-08-20 00:41:58,190 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.valid.0.pt
[2020-08-20 00:41:58,211 INFO] number of examples: 303
[2020-08-20 00:41:58,741 INFO] Validation perplexity: 1.24202
[2020-08-20 00:41:58,742 INFO] Validation accuracy: 91.1564
[2020-08-20 00:41:58,743 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv4/toy_model_step_10000.pt
[2020-08-20 00:42:00,096 INFO]  * src vocab size = 18
[2020-08-20 00:42:00,096 INFO]  * tgt vocab size = 18
[2020-08-20 00:42:00,096 INFO] Building model...
[2020-08-20 00:42:02,211 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=18, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 00:42:02,213 INFO] encoder: 5265408
[2020-08-20 00:42:02,213 INFO] decoder: 6320146
[2020-08-20 00:42:02,213 INFO] * number of parameters: 11585554
[2020-08-20 00:42:02,217 INFO] Starting training on GPU: [0]
[2020-08-20 00:42:02,217 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 00:42:02,217 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:42:02,241 INFO] number of examples: 4848
[2020-08-20 00:42:26,632 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_152.pt
[2020-08-20 00:42:51,046 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_304.pt
[2020-08-20 00:43:15,524 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_456.pt
[2020-08-20 00:43:17,210 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:43:17,256 INFO] number of examples: 4848
[2020-08-20 00:43:40,138 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_608.pt
[2020-08-20 00:44:04,545 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_760.pt
[2020-08-20 00:44:28,996 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_912.pt
[2020-08-20 00:44:31,909 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:44:31,930 INFO] number of examples: 4848
[2020-08-20 00:44:43,379 INFO] Step 1000/10000; acc:  80.32; ppl:  1.57; xent: 0.45; lr: 0.00140; 2482/1999 tok/s;    161 sec
[2020-08-20 00:44:53,531 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_1064.pt
[2020-08-20 00:45:17,858 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_1216.pt
[2020-08-20 00:45:42,269 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_1368.pt
[2020-08-20 00:45:46,308 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:45:46,354 INFO] number of examples: 4848
[2020-08-20 00:46:06,713 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_1520.pt
[2020-08-20 00:46:31,098 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_1672.pt
[2020-08-20 00:46:55,560 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_1824.pt
[2020-08-20 00:47:01,093 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:47:01,113 INFO] number of examples: 4848
[2020-08-20 00:47:20,016 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_1976.pt
[2020-08-20 00:47:24,169 INFO] Step 2000/10000; acc:  85.82; ppl:  1.35; xent: 0.30; lr: 0.00279; 2487/2003 tok/s;    322 sec
[2020-08-20 00:47:44,425 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_2128.pt
[2020-08-20 00:48:08,772 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_2280.pt
[2020-08-20 00:48:15,574 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:48:15,631 INFO] number of examples: 4848
[2020-08-20 00:48:33,245 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_2432.pt
[2020-08-20 00:48:57,631 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_2584.pt
[2020-08-20 00:49:22,043 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_2736.pt
[2020-08-20 00:49:30,088 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:49:30,110 INFO] number of examples: 4848
[2020-08-20 00:49:46,465 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_2888.pt
[2020-08-20 00:50:04,616 INFO] Step 3000/10000; acc:  85.51; ppl:  1.36; xent: 0.31; lr: 0.00228; 2494/2008 tok/s;    482 sec
[2020-08-20 00:50:10,939 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_3040.pt
[2020-08-20 00:50:35,861 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_3192.pt
[2020-08-20 00:50:45,222 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:50:45,273 INFO] number of examples: 4848
[2020-08-20 00:51:00,376 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_3344.pt
[2020-08-20 00:51:25,129 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_3496.pt
[2020-08-20 00:51:49,571 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_3648.pt
[2020-08-20 00:52:00,351 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:52:00,372 INFO] number of examples: 4848
[2020-08-20 00:52:14,018 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_3800.pt
[2020-08-20 00:52:38,494 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_3952.pt
[2020-08-20 00:52:46,404 INFO] Step 4000/10000; acc:  85.67; ppl:  1.35; xent: 0.30; lr: 0.00198; 2475/1992 tok/s;    644 sec
[2020-08-20 00:53:02,876 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_4104.pt
[2020-08-20 00:53:14,921 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:53:14,942 INFO] number of examples: 4848
[2020-08-20 00:53:27,342 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_4256.pt
[2020-08-20 00:53:52,422 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_4408.pt
[2020-08-20 00:54:16,802 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_4560.pt
[2020-08-20 00:54:30,316 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:54:30,337 INFO] number of examples: 4848
[2020-08-20 00:54:41,498 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_4712.pt
[2020-08-20 00:55:05,961 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_4864.pt
[2020-08-20 00:55:29,572 INFO] Step 5000/10000; acc:  84.40; ppl:  1.38; xent: 0.32; lr: 0.00177; 2451/1973 tok/s;    807 sec
[2020-08-20 00:55:32,115 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_5016.pt
[2020-08-20 00:55:46,693 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:55:46,714 INFO] number of examples: 4848
[2020-08-20 00:55:56,591 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_5168.pt
[2020-08-20 00:56:21,546 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_5320.pt
[2020-08-20 00:56:45,944 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_5472.pt
[2020-08-20 00:57:01,903 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:57:01,946 INFO] number of examples: 4848
[2020-08-20 00:57:10,384 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_5624.pt
[2020-08-20 00:57:34,759 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_5776.pt
[2020-08-20 00:57:59,056 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_5928.pt
[2020-08-20 00:58:10,769 INFO] Step 6000/10000; acc:  86.58; ppl:  1.31; xent: 0.27; lr: 0.00161; 2481/1997 tok/s;    969 sec
[2020-08-20 00:58:16,324 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:58:16,345 INFO] number of examples: 4848
[2020-08-20 00:58:23,501 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_6080.pt
[2020-08-20 00:58:47,969 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_6232.pt
[2020-08-20 00:59:12,459 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_6384.pt
[2020-08-20 00:59:30,929 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 00:59:30,977 INFO] number of examples: 4848
[2020-08-20 00:59:36,870 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_6536.pt
[2020-08-20 01:00:01,260 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_6688.pt
[2020-08-20 01:00:25,733 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_6840.pt
[2020-08-20 01:00:45,605 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:00:45,627 INFO] number of examples: 4848
[2020-08-20 01:00:50,240 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_6992.pt
[2020-08-20 01:00:51,822 INFO] Step 7000/10000; acc:  87.23; ppl:  1.29; xent: 0.26; lr: 0.00149; 2487/2003 tok/s;   1130 sec
[2020-08-20 01:01:14,758 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_7144.pt
[2020-08-20 01:01:39,274 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_7296.pt
[2020-08-20 01:02:00,536 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:02:00,586 INFO] number of examples: 4848
[2020-08-20 01:02:03,806 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_7448.pt
[2020-08-20 01:02:28,409 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_7600.pt
[2020-08-20 01:02:52,743 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_7752.pt
[2020-08-20 01:03:15,605 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:03:15,627 INFO] number of examples: 4848
[2020-08-20 01:03:17,572 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_7904.pt
[2020-08-20 01:03:33,247 INFO] Step 8000/10000; acc:  86.90; ppl:  1.30; xent: 0.27; lr: 0.00140; 2478/1995 tok/s;   1291 sec
[2020-08-20 01:03:42,158 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_8056.pt
[2020-08-20 01:04:06,591 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_8208.pt
[2020-08-20 01:04:30,379 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:04:30,427 INFO] number of examples: 4848
[2020-08-20 01:04:31,094 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_8360.pt
[2020-08-20 01:04:55,508 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_8512.pt
[2020-08-20 01:05:21,360 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_8664.pt
[2020-08-20 01:05:45,669 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_8816.pt
[2020-08-20 01:05:46,604 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:05:46,624 INFO] number of examples: 4848
[2020-08-20 01:06:09,947 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_8968.pt
[2020-08-20 01:06:15,366 INFO] Step 9000/10000; acc:  87.80; ppl:  1.28; xent: 0.24; lr: 0.00132; 2468/1988 tok/s;   1453 sec
[2020-08-20 01:06:34,152 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_9120.pt
[2020-08-20 01:06:58,203 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_9272.pt
[2020-08-20 01:07:00,606 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:07:00,655 INFO] number of examples: 4848
[2020-08-20 01:07:22,431 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_9424.pt
[2020-08-20 01:07:46,509 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_9576.pt
[2020-08-20 01:08:10,591 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_9728.pt
[2020-08-20 01:08:14,126 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:08:14,147 INFO] number of examples: 4848
[2020-08-20 01:08:34,633 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_9880.pt
[2020-08-20 01:08:54,456 INFO] Step 10000/10000; acc:  88.10; ppl:  1.27; xent: 0.24; lr: 0.00125; 2516/2025 tok/s;   1612 sec
[2020-08-20 01:08:54,457 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.valid.0.pt
[2020-08-20 01:08:54,460 INFO] number of examples: 303
[2020-08-20 01:08:54,989 INFO] Validation perplexity: 1.29923
[2020-08-20 01:08:54,989 INFO] Validation accuracy: 88.8948
[2020-08-20 01:08:54,991 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv5/toy_model_step_10000.pt
[2020-08-20 01:08:56,434 INFO]  * src vocab size = 18
[2020-08-20 01:08:56,435 INFO]  * tgt vocab size = 18
[2020-08-20 01:08:56,435 INFO] Building model...
[2020-08-20 01:08:58,563 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=18, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 01:08:58,565 INFO] encoder: 5265408
[2020-08-20 01:08:58,565 INFO] decoder: 6320146
[2020-08-20 01:08:58,565 INFO] * number of parameters: 11585554
[2020-08-20 01:08:58,573 INFO] Starting training on GPU: [0]
[2020-08-20 01:08:58,573 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 01:08:58,573 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:08:58,597 INFO] number of examples: 4848
[2020-08-20 01:09:22,847 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_152.pt
[2020-08-20 01:09:47,340 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_304.pt
[2020-08-20 01:10:12,589 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_456.pt
[2020-08-20 01:10:14,145 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:10:14,194 INFO] number of examples: 4848
[2020-08-20 01:10:37,052 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_608.pt
[2020-08-20 01:11:01,466 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_760.pt
[2020-08-20 01:11:26,998 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_912.pt
[2020-08-20 01:11:29,832 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:11:29,887 INFO] number of examples: 4848
[2020-08-20 01:11:41,303 INFO] Step 1000/10000; acc:  80.39; ppl:  1.56; xent: 0.45; lr: 0.00140; 2459/1980 tok/s;    163 sec
[2020-08-20 01:11:51,426 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_1064.pt
[2020-08-20 01:12:15,863 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_1216.pt
[2020-08-20 01:12:40,312 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_1368.pt
[2020-08-20 01:12:44,364 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:12:44,409 INFO] number of examples: 4848
[2020-08-20 01:13:04,709 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_1520.pt
[2020-08-20 01:13:29,227 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_1672.pt
[2020-08-20 01:13:53,791 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_1824.pt
[2020-08-20 01:13:59,431 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:13:59,452 INFO] number of examples: 4848
[2020-08-20 01:14:18,336 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_1976.pt
[2020-08-20 01:14:22,494 INFO] Step 2000/10000; acc:  85.46; ppl:  1.36; xent: 0.31; lr: 0.00279; 2484/1999 tok/s;    324 sec
[2020-08-20 01:14:42,784 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_2128.pt
[2020-08-20 01:15:08,255 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_2280.pt
[2020-08-20 01:15:15,061 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:15:15,123 INFO] number of examples: 4848
[2020-08-20 01:15:32,732 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_2432.pt
[2020-08-20 01:15:57,119 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_2584.pt
[2020-08-20 01:16:22,393 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_2736.pt
[2020-08-20 01:16:30,588 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:16:30,610 INFO] number of examples: 4848
[2020-08-20 01:16:46,902 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_2888.pt
[2020-08-20 01:17:04,823 INFO] Step 3000/10000; acc:  85.85; ppl:  1.34; xent: 0.30; lr: 0.00228; 2463/1984 tok/s;    486 sec
[2020-08-20 01:17:11,139 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_3040.pt
[2020-08-20 01:17:35,480 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_3192.pt
[2020-08-20 01:17:44,838 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:17:44,888 INFO] number of examples: 4848
[2020-08-20 01:17:59,956 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_3344.pt
[2020-08-20 01:18:24,321 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_3496.pt
[2020-08-20 01:18:48,659 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_3648.pt
[2020-08-20 01:18:59,454 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:18:59,476 INFO] number of examples: 4848
[2020-08-20 01:19:13,092 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_3800.pt
[2020-08-20 01:19:37,538 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_3952.pt
[2020-08-20 01:19:45,412 INFO] Step 4000/10000; acc:  86.00; ppl:  1.33; xent: 0.29; lr: 0.00198; 2494/2009 tok/s;    647 sec
[2020-08-20 01:20:01,890 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_4104.pt
[2020-08-20 01:20:13,981 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:20:14,003 INFO] number of examples: 4848
[2020-08-20 01:20:26,411 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_4256.pt
[2020-08-20 01:20:50,685 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_4408.pt
[2020-08-20 01:21:15,117 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_4560.pt
[2020-08-20 01:21:30,066 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:21:30,087 INFO] number of examples: 4848
[2020-08-20 01:21:41,184 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_4712.pt
[2020-08-20 01:22:05,593 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_4864.pt
[2020-08-20 01:22:27,350 INFO] Step 5000/10000; acc:  86.65; ppl:  1.31; xent: 0.27; lr: 0.00177; 2470/1989 tok/s;    809 sec
[2020-08-20 01:22:29,860 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_5016.pt
[2020-08-20 01:22:44,320 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:22:44,342 INFO] number of examples: 4848
[2020-08-20 01:22:54,079 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_5168.pt
[2020-08-20 01:23:18,155 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_5320.pt
[2020-08-20 01:23:42,200 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_5472.pt
[2020-08-20 01:23:57,983 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:23:58,027 INFO] number of examples: 4848
[2020-08-20 01:24:06,328 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_5624.pt
[2020-08-20 01:24:30,374 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_5776.pt
[2020-08-20 01:24:54,381 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_5928.pt
[2020-08-20 01:25:05,885 INFO] Step 6000/10000; acc:  86.53; ppl:  1.31; xent: 0.27; lr: 0.00161; 2524/2032 tok/s;    967 sec
[2020-08-20 01:25:11,362 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:25:11,392 INFO] number of examples: 4848
[2020-08-20 01:25:18,448 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_6080.pt
[2020-08-20 01:25:42,474 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_6232.pt
[2020-08-20 01:26:06,476 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_6384.pt
[2020-08-20 01:26:24,674 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:26:24,718 INFO] number of examples: 4848
[2020-08-20 01:26:30,527 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_6536.pt
[2020-08-20 01:26:54,571 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_6688.pt
[2020-08-20 01:27:18,620 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_6840.pt
[2020-08-20 01:27:38,074 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:27:38,096 INFO] number of examples: 4848
[2020-08-20 01:27:42,637 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_6992.pt
[2020-08-20 01:27:44,324 INFO] Step 7000/10000; acc:  86.72; ppl:  1.30; xent: 0.26; lr: 0.00149; 2525/2033 tok/s;   1126 sec
[2020-08-20 01:28:06,750 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_7144.pt
[2020-08-20 01:28:30,730 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_7296.pt
[2020-08-20 01:28:51,627 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:28:51,673 INFO] number of examples: 4848
[2020-08-20 01:28:54,821 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_7448.pt
[2020-08-20 01:29:18,899 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_7600.pt
[2020-08-20 01:29:42,852 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_7752.pt
[2020-08-20 01:30:05,031 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:30:05,052 INFO] number of examples: 4848
[2020-08-20 01:30:06,957 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_7904.pt
[2020-08-20 01:30:22,790 INFO] Step 8000/10000; acc:  87.12; ppl:  1.29; xent: 0.25; lr: 0.00140; 2524/2032 tok/s;   1284 sec
[2020-08-20 01:30:31,505 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_8056.pt
[2020-08-20 01:30:55,491 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_8208.pt
[2020-08-20 01:31:18,890 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:31:18,938 INFO] number of examples: 4848
[2020-08-20 01:31:19,601 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_8360.pt
[2020-08-20 01:31:43,640 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_8512.pt
[2020-08-20 01:32:07,792 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_8664.pt
[2020-08-20 01:32:31,868 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_8816.pt
[2020-08-20 01:32:32,896 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:32:32,918 INFO] number of examples: 4848
[2020-08-20 01:32:55,985 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_8968.pt
[2020-08-20 01:33:01,250 INFO] Step 9000/10000; acc:  87.47; ppl:  1.28; xent: 0.25; lr: 0.00132; 2525/2034 tok/s;   1443 sec
[2020-08-20 01:33:19,945 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_9120.pt
[2020-08-20 01:33:43,920 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_9272.pt
[2020-08-20 01:33:46,382 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:33:46,431 INFO] number of examples: 4848
[2020-08-20 01:34:08,107 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_9424.pt
[2020-08-20 01:34:32,899 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_9576.pt
[2020-08-20 01:34:56,663 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_9728.pt
[2020-08-20 01:35:00,265 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:35:00,287 INFO] number of examples: 4848
[2020-08-20 01:35:20,561 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_9880.pt
[2020-08-20 01:35:39,362 INFO] Step 10000/10000; acc:  87.44; ppl:  1.28; xent: 0.25; lr: 0.00125; 2532/2039 tok/s;   1601 sec
[2020-08-20 01:35:39,363 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.valid.0.pt
[2020-08-20 01:35:39,384 INFO] number of examples: 303
[2020-08-20 01:35:39,911 INFO] Validation perplexity: 1.33311
[2020-08-20 01:35:39,911 INFO] Validation accuracy: 88.7028
[2020-08-20 01:35:39,913 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv6/toy_model_step_10000.pt
[2020-08-20 01:35:41,332 INFO]  * src vocab size = 18
[2020-08-20 01:35:41,332 INFO]  * tgt vocab size = 18
[2020-08-20 01:35:41,332 INFO] Building model...
[2020-08-20 01:35:43,455 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=18, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 01:35:43,457 INFO] encoder: 5265408
[2020-08-20 01:35:43,457 INFO] decoder: 6320146
[2020-08-20 01:35:43,458 INFO] * number of parameters: 11585554
[2020-08-20 01:35:43,468 INFO] Starting training on GPU: [0]
[2020-08-20 01:35:43,468 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 01:35:43,468 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:35:43,493 INFO] number of examples: 4848
[2020-08-20 01:36:06,938 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_152.pt
[2020-08-20 01:36:30,402 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_304.pt
[2020-08-20 01:36:53,853 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_456.pt
[2020-08-20 01:36:55,366 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:36:55,413 INFO] number of examples: 4848
[2020-08-20 01:37:17,428 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_608.pt
[2020-08-20 01:37:40,992 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_760.pt
[2020-08-20 01:38:04,560 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_912.pt
[2020-08-20 01:38:07,316 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:38:07,337 INFO] number of examples: 4848
[2020-08-20 01:38:18,362 INFO] Step 1000/10000; acc:  80.35; ppl:  1.56; xent: 0.45; lr: 0.00140; 2584/2081 tok/s;    155 sec
[2020-08-20 01:38:28,146 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_1064.pt
[2020-08-20 01:38:51,614 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_1216.pt
[2020-08-20 01:39:15,042 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_1368.pt
[2020-08-20 01:39:19,088 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:39:19,135 INFO] number of examples: 4848
[2020-08-20 01:39:38,715 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_1520.pt
[2020-08-20 01:40:02,152 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_1672.pt
[2020-08-20 01:40:25,787 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_1824.pt
[2020-08-20 01:40:31,190 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:40:31,211 INFO] number of examples: 4848
[2020-08-20 01:40:49,433 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_1976.pt
[2020-08-20 01:40:53,358 INFO] Step 2000/10000; acc:  85.69; ppl:  1.35; xent: 0.30; lr: 0.00279; 2581/2078 tok/s;    310 sec
[2020-08-20 01:41:12,902 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_2128.pt
[2020-08-20 01:41:37,195 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_2280.pt
[2020-08-20 01:41:43,865 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:41:43,915 INFO] number of examples: 4848
[2020-08-20 01:42:00,910 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_2432.pt
[2020-08-20 01:42:24,369 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_2584.pt
[2020-08-20 01:42:47,945 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_2736.pt
[2020-08-20 01:42:55,782 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:42:55,804 INFO] number of examples: 4848
[2020-08-20 01:43:11,589 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_2888.pt
[2020-08-20 01:43:28,997 INFO] Step 3000/10000; acc:  86.24; ppl:  1.34; xent: 0.29; lr: 0.00228; 2568/2067 tok/s;    466 sec
[2020-08-20 01:43:35,120 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_3040.pt
[2020-08-20 01:43:58,759 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_3192.pt
[2020-08-20 01:44:07,805 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:44:07,855 INFO] number of examples: 4848
[2020-08-20 01:44:22,409 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_3344.pt
[2020-08-20 01:44:45,940 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_3496.pt
[2020-08-20 01:45:09,714 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_3648.pt
[2020-08-20 01:45:20,084 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:45:20,149 INFO] number of examples: 4848
[2020-08-20 01:45:33,327 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_3800.pt
[2020-08-20 01:45:56,841 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_3952.pt
[2020-08-20 01:46:04,484 INFO] Step 4000/10000; acc:  86.72; ppl:  1.32; xent: 0.27; lr: 0.00198; 2574/2072 tok/s;    621 sec
[2020-08-20 01:46:20,386 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_4104.pt
[2020-08-20 01:46:31,937 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:46:31,959 INFO] number of examples: 4848
[2020-08-20 01:46:43,911 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_4256.pt
[2020-08-20 01:47:07,434 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_4408.pt
[2020-08-20 01:47:30,998 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_4560.pt
[2020-08-20 01:47:43,798 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:47:43,820 INFO] number of examples: 4848
[2020-08-20 01:47:54,573 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_4712.pt
[2020-08-20 01:48:18,115 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_4864.pt
[2020-08-20 01:48:39,233 INFO] Step 5000/10000; acc:  87.26; ppl:  1.30; xent: 0.26; lr: 0.00177; 2586/2082 tok/s;    776 sec
[2020-08-20 01:48:41,678 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_5016.pt
[2020-08-20 01:48:55,728 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:48:55,753 INFO] number of examples: 4848
[2020-08-20 01:49:05,262 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_5168.pt
[2020-08-20 01:49:28,783 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_5320.pt
[2020-08-20 01:49:53,191 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_5472.pt
[2020-08-20 01:50:08,617 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:50:08,665 INFO] number of examples: 4848
[2020-08-20 01:50:16,795 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_5624.pt
[2020-08-20 01:50:41,232 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_5776.pt
[2020-08-20 01:51:04,853 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_5928.pt
[2020-08-20 01:51:16,212 INFO] Step 6000/10000; acc:  87.46; ppl:  1.29; xent: 0.25; lr: 0.00161; 2549/2053 tok/s;    933 sec
[2020-08-20 01:51:21,562 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:51:21,584 INFO] number of examples: 4848
[2020-08-20 01:51:28,491 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_6080.pt
[2020-08-20 01:51:52,068 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_6232.pt
[2020-08-20 01:52:15,556 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_6384.pt
[2020-08-20 01:52:33,608 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:52:33,653 INFO] number of examples: 4848
[2020-08-20 01:52:39,348 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_6536.pt
[2020-08-20 01:53:02,902 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_6688.pt
[2020-08-20 01:53:26,492 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_6840.pt
[2020-08-20 01:53:45,610 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:53:45,633 INFO] number of examples: 4848
[2020-08-20 01:53:50,093 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_6992.pt
[2020-08-20 01:53:51,719 INFO] Step 7000/10000; acc:  87.78; ppl:  1.28; xent: 0.25; lr: 0.00149; 2575/2074 tok/s;   1088 sec
[2020-08-20 01:54:13,704 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_7144.pt
[2020-08-20 01:54:37,316 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_7296.pt
[2020-08-20 01:54:57,901 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:54:57,949 INFO] number of examples: 4848
[2020-08-20 01:55:01,031 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_7448.pt
[2020-08-20 01:55:24,749 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_7600.pt
[2020-08-20 01:55:48,297 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_7752.pt
[2020-08-20 01:56:10,067 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:56:10,090 INFO] number of examples: 4848
[2020-08-20 01:56:11,949 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_7904.pt
[2020-08-20 01:56:26,948 INFO] Step 8000/10000; acc:  87.54; ppl:  1.28; xent: 0.25; lr: 0.00140; 2578/2076 tok/s;   1243 sec
[2020-08-20 01:56:35,514 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_8056.pt
[2020-08-20 01:56:58,955 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_8208.pt
[2020-08-20 01:57:21,960 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:57:22,009 INFO] number of examples: 4848
[2020-08-20 01:57:22,654 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_8360.pt
[2020-08-20 01:57:46,132 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_8512.pt
[2020-08-20 01:58:12,396 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_8664.pt
[2020-08-20 01:58:35,701 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_8816.pt
[2020-08-20 01:58:36,650 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:58:36,674 INFO] number of examples: 4848
[2020-08-20 01:58:58,967 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_8968.pt
[2020-08-20 01:59:04,037 INFO] Step 9000/10000; acc:  88.12; ppl:  1.27; xent: 0.24; lr: 0.00132; 2546/2050 tok/s;   1401 sec
[2020-08-20 01:59:22,074 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_9120.pt
[2020-08-20 01:59:46,085 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_9272.pt
[2020-08-20 01:59:48,393 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 01:59:48,444 INFO] number of examples: 4848
[2020-08-20 02:00:09,414 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_9424.pt
[2020-08-20 02:00:32,660 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_9576.pt
[2020-08-20 02:00:55,838 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_9728.pt
[2020-08-20 02:00:59,262 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:00:59,285 INFO] number of examples: 4848
[2020-08-20 02:01:19,075 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_9880.pt
[2020-08-20 02:01:37,418 INFO] Step 10000/10000; acc:  87.97; ppl:  1.27; xent: 0.24; lr: 0.00125; 2606/2098 tok/s;   1554 sec
[2020-08-20 02:01:37,419 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.valid.0.pt
[2020-08-20 02:01:37,422 INFO] number of examples: 303
[2020-08-20 02:01:37,943 INFO] Validation perplexity: 1.27744
[2020-08-20 02:01:37,943 INFO] Validation accuracy: 90.6763
[2020-08-20 02:01:37,945 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv7/toy_model_step_10000.pt
[2020-08-20 02:01:39,534 INFO]  * src vocab size = 18
[2020-08-20 02:01:39,534 INFO]  * tgt vocab size = 18
[2020-08-20 02:01:39,534 INFO] Building model...
[2020-08-20 02:01:41,708 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=18, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 02:01:41,710 INFO] encoder: 5265408
[2020-08-20 02:01:41,710 INFO] decoder: 6320146
[2020-08-20 02:01:41,710 INFO] * number of parameters: 11585554
[2020-08-20 02:01:41,723 INFO] Starting training on GPU: [0]
[2020-08-20 02:01:41,723 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 02:01:41,723 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:01:41,747 INFO] number of examples: 4848
[2020-08-20 02:02:06,300 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_152.pt
[2020-08-20 02:02:30,857 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_304.pt
[2020-08-20 02:02:55,569 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_456.pt
[2020-08-20 02:02:57,335 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:02:57,381 INFO] number of examples: 4848
[2020-08-20 02:03:20,448 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_608.pt
[2020-08-20 02:03:45,100 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_760.pt
[2020-08-20 02:04:09,641 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_912.pt
[2020-08-20 02:04:12,590 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:04:12,611 INFO] number of examples: 4848
[2020-08-20 02:04:24,168 INFO] Step 1000/10000; acc:  80.34; ppl:  1.56; xent: 0.44; lr: 0.00140; 2463/1983 tok/s;    162 sec
[2020-08-20 02:04:34,395 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_1064.pt
[2020-08-20 02:04:59,131 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_1216.pt
[2020-08-20 02:05:24,723 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_1368.pt
[2020-08-20 02:05:29,701 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:05:29,747 INFO] number of examples: 4848
[2020-08-20 02:05:50,230 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_1520.pt
[2020-08-20 02:06:14,841 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_1672.pt
[2020-08-20 02:06:39,512 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_1824.pt
[2020-08-20 02:06:45,100 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:06:45,122 INFO] number of examples: 4848
[2020-08-20 02:07:04,130 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_1976.pt
[2020-08-20 02:07:08,338 INFO] Step 2000/10000; acc:  85.63; ppl:  1.35; xent: 0.30; lr: 0.00279; 2439/1964 tok/s;    327 sec
[2020-08-20 02:07:28,802 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_2128.pt
[2020-08-20 02:07:56,710 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_2280.pt
[2020-08-20 02:08:03,559 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:08:03,609 INFO] number of examples: 4848
[2020-08-20 02:08:21,393 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_2432.pt
[2020-08-20 02:08:46,020 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_2584.pt
[2020-08-20 02:09:10,728 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_2736.pt
[2020-08-20 02:09:23,499 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:09:23,520 INFO] number of examples: 4848
[2020-08-20 02:09:39,998 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_2888.pt
[2020-08-20 02:10:03,060 INFO] Step 3000/10000; acc:  86.40; ppl:  1.33; xent: 0.28; lr: 0.00228; 2289/1843 tok/s;    501 sec
[2020-08-20 02:10:09,444 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_3040.pt
[2020-08-20 02:10:34,111 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_3192.pt
[2020-08-20 02:10:43,531 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:10:43,581 INFO] number of examples: 4848
[2020-08-20 02:10:58,769 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_3344.pt
[2020-08-20 02:11:23,382 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_3496.pt
[2020-08-20 02:11:48,030 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_3648.pt
[2020-08-20 02:11:58,974 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:11:58,996 INFO] number of examples: 4848
[2020-08-20 02:12:12,753 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_3800.pt
[2020-08-20 02:12:37,515 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_3952.pt
[2020-08-20 02:12:45,473 INFO] Step 4000/10000; acc:  87.14; ppl:  1.30; xent: 0.26; lr: 0.00198; 2465/1985 tok/s;    664 sec
[2020-08-20 02:13:02,046 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_4104.pt
[2020-08-20 02:13:14,192 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:13:14,214 INFO] number of examples: 4848
[2020-08-20 02:13:26,699 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_4256.pt
[2020-08-20 02:13:51,274 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_4408.pt
[2020-08-20 02:14:15,844 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_4560.pt
[2020-08-20 02:14:29,273 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:14:29,295 INFO] number of examples: 4848
[2020-08-20 02:14:40,467 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_4712.pt
[2020-08-20 02:15:04,974 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_4864.pt
[2020-08-20 02:15:26,741 INFO] Step 5000/10000; acc:  87.43; ppl:  1.29; xent: 0.25; lr: 0.00177; 2480/1996 tok/s;    825 sec
[2020-08-20 02:15:29,268 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_5016.pt
[2020-08-20 02:15:43,894 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:15:43,915 INFO] number of examples: 4848
[2020-08-20 02:15:53,692 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_5168.pt
[2020-08-20 02:16:17,877 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_5320.pt
[2020-08-20 02:16:41,884 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_5472.pt
[2020-08-20 02:16:57,734 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:16:57,777 INFO] number of examples: 4848
[2020-08-20 02:17:06,125 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_5624.pt
[2020-08-20 02:17:30,290 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_5776.pt
[2020-08-20 02:17:54,548 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_5928.pt
[2020-08-20 02:18:06,174 INFO] Step 6000/10000; acc:  87.60; ppl:  1.28; xent: 0.25; lr: 0.00161; 2510/2021 tok/s;    984 sec
[2020-08-20 02:18:11,668 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:18:11,689 INFO] number of examples: 4848
[2020-08-20 02:18:18,756 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_6080.pt
[2020-08-20 02:18:43,041 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_6232.pt
[2020-08-20 02:19:07,278 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_6384.pt
[2020-08-20 02:19:25,759 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:19:25,802 INFO] number of examples: 4848
[2020-08-20 02:19:31,652 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_6536.pt
[2020-08-20 02:19:55,914 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_6688.pt
[2020-08-20 02:20:20,094 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_6840.pt
[2020-08-20 02:20:39,713 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:20:39,735 INFO] number of examples: 4848
[2020-08-20 02:20:44,313 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_6992.pt
[2020-08-20 02:20:45,833 INFO] Step 7000/10000; acc:  87.97; ppl:  1.27; xent: 0.24; lr: 0.00149; 2505/2017 tok/s;   1144 sec
[2020-08-20 02:21:08,582 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_7144.pt
[2020-08-20 02:21:32,850 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_7296.pt
[2020-08-20 02:21:54,741 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:21:54,787 INFO] number of examples: 4848
[2020-08-20 02:21:57,967 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_7448.pt
[2020-08-20 02:22:22,246 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_7600.pt
[2020-08-20 02:22:46,417 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_7752.pt
[2020-08-20 02:23:09,573 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:23:09,594 INFO] number of examples: 4848
[2020-08-20 02:23:11,535 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_7904.pt
[2020-08-20 02:23:26,957 INFO] Step 8000/10000; acc:  88.30; ppl:  1.26; xent: 0.23; lr: 0.00140; 2484/2001 tok/s;   1305 sec
[2020-08-20 02:23:35,772 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_8056.pt
[2020-08-20 02:23:59,926 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_8208.pt
[2020-08-20 02:24:23,624 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:24:23,670 INFO] number of examples: 4848
[2020-08-20 02:24:24,332 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_8360.pt
[2020-08-20 02:24:48,567 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_8512.pt
[2020-08-20 02:25:12,839 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_8664.pt
[2020-08-20 02:25:37,088 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_8816.pt
[2020-08-20 02:25:38,230 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:25:38,253 INFO] number of examples: 4848
[2020-08-20 02:26:01,533 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_8968.pt
[2020-08-20 02:26:06,949 INFO] Step 9000/10000; acc:  88.34; ppl:  1.27; xent: 0.24; lr: 0.00132; 2501/2014 tok/s;   1465 sec
[2020-08-20 02:26:25,820 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_9120.pt
[2020-08-20 02:26:49,976 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_9272.pt
[2020-08-20 02:26:52,382 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:26:52,430 INFO] number of examples: 4848
[2020-08-20 02:27:14,173 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_9424.pt
[2020-08-20 02:27:38,203 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_9576.pt
[2020-08-20 02:28:02,264 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_9728.pt
[2020-08-20 02:28:05,858 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:28:05,880 INFO] number of examples: 4848
[2020-08-20 02:28:26,289 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_9880.pt
[2020-08-20 02:28:45,272 INFO] Step 10000/10000; acc:  88.90; ppl:  1.25; xent: 0.22; lr: 0.00125; 2528/2036 tok/s;   1624 sec
[2020-08-20 02:28:45,273 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.valid.0.pt
[2020-08-20 02:28:45,363 INFO] number of examples: 303
[2020-08-20 02:28:45,889 INFO] Validation perplexity: 1.26579
[2020-08-20 02:28:45,889 INFO] Validation accuracy: 90.495
[2020-08-20 02:28:45,890 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv8/toy_model_step_10000.pt
[2020-08-20 02:28:47,302 INFO]  * src vocab size = 18
[2020-08-20 02:28:47,302 INFO]  * tgt vocab size = 18
[2020-08-20 02:28:47,302 INFO] Building model...
[2020-08-20 02:28:49,418 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=18, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 02:28:49,420 INFO] encoder: 5265408
[2020-08-20 02:28:49,420 INFO] decoder: 6320146
[2020-08-20 02:28:49,420 INFO] * number of parameters: 11585554
[2020-08-20 02:28:49,425 INFO] Starting training on GPU: [0]
[2020-08-20 02:28:49,425 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 02:28:49,425 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:28:49,449 INFO] number of examples: 4848
[2020-08-20 02:29:13,937 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_152.pt
[2020-08-20 02:29:38,620 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_304.pt
[2020-08-20 02:30:03,162 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_456.pt
[2020-08-20 02:30:05,372 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:30:05,423 INFO] number of examples: 4848
[2020-08-20 02:30:28,466 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_608.pt
[2020-08-20 02:30:53,536 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_760.pt
[2020-08-20 02:31:19,654 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_912.pt
[2020-08-20 02:31:22,482 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:31:22,502 INFO] number of examples: 4848
[2020-08-20 02:31:34,046 INFO] Step 1000/10000; acc:  80.28; ppl:  1.56; xent: 0.44; lr: 0.00140; 2433/1959 tok/s;    165 sec
[2020-08-20 02:31:44,268 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_1064.pt
[2020-08-20 02:32:08,970 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_1216.pt
[2020-08-20 02:32:33,637 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_1368.pt
[2020-08-20 02:32:37,881 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:32:37,929 INFO] number of examples: 4848
[2020-08-20 02:32:58,433 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_1520.pt
[2020-08-20 02:33:23,103 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_1672.pt
[2020-08-20 02:33:47,683 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_1824.pt
[2020-08-20 02:33:53,281 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:33:54,320 INFO] number of examples: 4848
[2020-08-20 02:34:13,384 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_1976.pt
[2020-08-20 02:34:17,470 INFO] Step 2000/10000; acc:  85.46; ppl:  1.36; xent: 0.31; lr: 0.00279; 2447/1971 tok/s;    328 sec
[2020-08-20 02:34:37,929 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_2128.pt
[2020-08-20 02:35:02,502 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_2280.pt
[2020-08-20 02:35:09,389 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:35:09,437 INFO] number of examples: 4848
[2020-08-20 02:35:27,239 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_2432.pt
[2020-08-20 02:35:51,785 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_2584.pt
[2020-08-20 02:36:16,459 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_2736.pt
[2020-08-20 02:36:24,602 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:36:24,627 INFO] number of examples: 4848
[2020-08-20 02:36:41,120 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_2888.pt
[2020-08-20 02:36:59,307 INFO] Step 3000/10000; acc:  85.47; ppl:  1.36; xent: 0.31; lr: 0.00228; 2474/1992 tok/s;    490 sec
[2020-08-20 02:37:05,705 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_3040.pt
[2020-08-20 02:37:30,288 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_3192.pt
[2020-08-20 02:37:40,642 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:37:40,692 INFO] number of examples: 4848
[2020-08-20 02:37:55,945 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_3344.pt
[2020-08-20 02:38:20,539 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_3496.pt
[2020-08-20 02:38:45,140 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_3648.pt
[2020-08-20 02:38:55,980 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:38:56,001 INFO] number of examples: 4848
[2020-08-20 02:39:09,742 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_3800.pt
[2020-08-20 02:39:34,384 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_3952.pt
[2020-08-20 02:39:42,413 INFO] Step 4000/10000; acc:  86.64; ppl:  1.32; xent: 0.28; lr: 0.00198; 2453/1975 tok/s;    653 sec
[2020-08-20 02:39:59,013 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_4104.pt
[2020-08-20 02:40:11,130 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:40:11,152 INFO] number of examples: 4848
[2020-08-20 02:40:23,679 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_4256.pt
[2020-08-20 02:41:02,697 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_4408.pt
[2020-08-20 02:41:27,319 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_4560.pt
[2020-08-20 02:41:40,769 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:41:40,791 INFO] number of examples: 4848
[2020-08-20 02:41:52,013 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_4712.pt
[2020-08-20 02:42:16,611 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_4864.pt
[2020-08-20 02:42:38,766 INFO] Step 5000/10000; acc:  86.86; ppl:  1.31; xent: 0.27; lr: 0.00177; 2267/1825 tok/s;    829 sec
[2020-08-20 02:42:41,320 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_5016.pt
[2020-08-20 02:42:56,007 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:42:56,029 INFO] number of examples: 4848
[2020-08-20 02:43:05,978 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_5168.pt
[2020-08-20 02:43:30,608 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_5320.pt
[2020-08-20 02:43:55,128 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_5472.pt
[2020-08-20 02:44:11,406 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:44:11,450 INFO] number of examples: 4848
[2020-08-20 02:44:19,951 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_5624.pt
[2020-08-20 02:44:44,543 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_5776.pt
[2020-08-20 02:45:09,262 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_5928.pt
[2020-08-20 02:45:22,468 INFO] Step 6000/10000; acc:  87.47; ppl:  1.29; xent: 0.25; lr: 0.00161; 2444/1968 tok/s;    993 sec
[2020-08-20 02:45:28,055 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:45:28,077 INFO] number of examples: 4848
[2020-08-20 02:45:35,305 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_6080.pt
[2020-08-20 02:45:59,937 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_6232.pt
[2020-08-20 02:46:24,629 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_6384.pt
[2020-08-20 02:46:43,304 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:46:43,538 INFO] number of examples: 4848
[2020-08-20 02:46:49,478 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_6536.pt
[2020-08-20 02:47:14,090 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_6688.pt
[2020-08-20 02:47:38,715 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_6840.pt
[2020-08-20 02:47:59,684 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:47:59,705 INFO] number of examples: 4848
[2020-08-20 02:48:04,374 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_6992.pt
[2020-08-20 02:48:07,146 INFO] Step 7000/10000; acc:  87.37; ppl:  1.29; xent: 0.25; lr: 0.00149; 2433/1959 tok/s;   1158 sec
[2020-08-20 02:48:30,128 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_7144.pt
[2020-08-20 02:48:54,751 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_7296.pt
[2020-08-20 02:49:16,306 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:49:16,358 INFO] number of examples: 4848
[2020-08-20 02:49:19,614 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_7448.pt
[2020-08-20 02:49:44,189 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_7600.pt
[2020-08-20 02:50:08,642 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_7752.pt
[2020-08-20 02:50:31,245 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:50:31,266 INFO] number of examples: 4848
[2020-08-20 02:50:33,176 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_7904.pt
[2020-08-20 02:50:48,611 INFO] Step 8000/10000; acc:  87.82; ppl:  1.27; xent: 0.24; lr: 0.00140; 2478/1995 tok/s;   1319 sec
[2020-08-20 02:50:57,437 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_8056.pt
[2020-08-20 02:51:21,844 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_8208.pt
[2020-08-20 02:51:45,424 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:51:45,476 INFO] number of examples: 4848
[2020-08-20 02:51:46,147 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_8360.pt
[2020-08-20 02:52:10,424 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_8512.pt
[2020-08-20 02:52:37,506 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_8664.pt
[2020-08-20 02:53:02,397 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_8816.pt
[2020-08-20 02:53:03,315 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:53:03,336 INFO] number of examples: 4848
[2020-08-20 02:53:26,680 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_8968.pt
[2020-08-20 02:53:32,047 INFO] Step 9000/10000; acc:  87.59; ppl:  1.28; xent: 0.25; lr: 0.00132; 2450/1972 tok/s;   1483 sec
[2020-08-20 02:53:50,990 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_9120.pt
[2020-08-20 02:54:15,257 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_9272.pt
[2020-08-20 02:54:18,007 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:54:18,054 INFO] number of examples: 4848
[2020-08-20 02:54:40,025 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_9424.pt
[2020-08-20 02:55:04,508 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_9576.pt
[2020-08-20 02:55:28,833 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_9728.pt
[2020-08-20 02:55:32,501 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:55:32,523 INFO] number of examples: 4848
[2020-08-20 02:55:53,220 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_9880.pt
[2020-08-20 02:56:13,351 INFO] Step 10000/10000; acc:  87.50; ppl:  1.29; xent: 0.25; lr: 0.00125; 2479/1996 tok/s;   1644 sec
[2020-08-20 02:56:13,352 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.valid.0.pt
[2020-08-20 02:56:13,355 INFO] number of examples: 303
[2020-08-20 02:56:13,889 INFO] Validation perplexity: 1.35433
[2020-08-20 02:56:13,889 INFO] Validation accuracy: 87.8494
[2020-08-20 02:56:13,891 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv9/toy_model_step_10000.pt
[2020-08-20 02:56:15,522 INFO]  * src vocab size = 18
[2020-08-20 02:56:15,522 INFO]  * tgt vocab size = 18
[2020-08-20 02:56:15,522 INFO] Building model...
[2020-08-20 02:56:17,658 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(18, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=18, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 02:56:17,660 INFO] encoder: 5265408
[2020-08-20 02:56:17,661 INFO] decoder: 6320146
[2020-08-20 02:56:17,661 INFO] * number of parameters: 11585554
[2020-08-20 02:56:17,667 INFO] Starting training on GPU: [0]
[2020-08-20 02:56:17,668 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 02:56:17,668 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:56:17,692 INFO] number of examples: 4848
[2020-08-20 02:56:42,269 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_152.pt
[2020-08-20 02:57:06,948 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_304.pt
[2020-08-20 02:57:31,538 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_456.pt
[2020-08-20 02:57:33,232 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:57:33,278 INFO] number of examples: 4848
[2020-08-20 02:57:56,402 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_608.pt
[2020-08-20 02:58:21,056 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_760.pt
[2020-08-20 02:58:45,842 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_912.pt
[2020-08-20 02:58:49,805 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 02:58:49,826 INFO] number of examples: 4848
[2020-08-20 02:59:01,390 INFO] Step 1000/10000; acc:  80.31; ppl:  1.57; xent: 0.45; lr: 0.00140; 2446/1969 tok/s;    164 sec
[2020-08-20 02:59:11,655 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_1064.pt
[2020-08-20 02:59:36,297 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_1216.pt
[2020-08-20 03:00:04,087 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_1368.pt
[2020-08-20 03:00:08,260 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:00:08,309 INFO] number of examples: 4848
[2020-08-20 03:00:28,899 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_1520.pt
[2020-08-20 03:00:55,406 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_1672.pt
[2020-08-20 03:01:20,131 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_1824.pt
[2020-08-20 03:01:27,127 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:01:27,147 INFO] number of examples: 4848
[2020-08-20 03:01:46,287 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_1976.pt
[2020-08-20 03:01:50,442 INFO] Step 2000/10000; acc:  85.46; ppl:  1.36; xent: 0.31; lr: 0.00279; 2367/1907 tok/s;    333 sec
[2020-08-20 03:02:11,030 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_2128.pt
[2020-08-20 03:02:35,659 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_2280.pt
[2020-08-20 03:02:42,573 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:02:42,621 INFO] number of examples: 4848
[2020-08-20 03:03:00,530 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_2432.pt
[2020-08-20 03:03:25,210 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_2584.pt
[2020-08-20 03:03:49,959 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_2736.pt
[2020-08-20 03:03:58,207 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:03:58,229 INFO] number of examples: 4848
[2020-08-20 03:04:14,744 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_2888.pt
[2020-08-20 03:04:33,145 INFO] Step 3000/10000; acc:  85.92; ppl:  1.34; xent: 0.30; lr: 0.00228; 2460/1981 tok/s;    495 sec
[2020-08-20 03:04:39,568 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_3040.pt
[2020-08-20 03:05:04,192 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_3192.pt
[2020-08-20 03:05:14,515 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:05:14,565 INFO] number of examples: 4848
[2020-08-20 03:05:29,830 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_3344.pt
[2020-08-20 03:05:54,518 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_3496.pt
[2020-08-20 03:06:19,237 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_3648.pt
[2020-08-20 03:06:30,063 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:06:30,086 INFO] number of examples: 4848
[2020-08-20 03:06:43,880 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_3800.pt
[2020-08-20 03:07:08,511 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_3952.pt
[2020-08-20 03:07:16,478 INFO] Step 4000/10000; acc:  86.20; ppl:  1.33; xent: 0.29; lr: 0.00198; 2447/1970 tok/s;    659 sec
[2020-08-20 03:07:33,136 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_4104.pt
[2020-08-20 03:07:45,260 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:07:45,283 INFO] number of examples: 4848
[2020-08-20 03:07:57,813 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_4256.pt
[2020-08-20 03:08:22,569 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_4408.pt
[2020-08-20 03:08:48,116 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_4560.pt
[2020-08-20 03:09:01,563 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:09:01,585 INFO] number of examples: 4848
[2020-08-20 03:09:12,844 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_4712.pt
[2020-08-20 03:09:37,370 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_4864.pt
[2020-08-20 03:09:59,384 INFO] Step 5000/10000; acc:  87.33; ppl:  1.29; xent: 0.26; lr: 0.00177; 2457/1979 tok/s;    822 sec
[2020-08-20 03:10:01,952 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_5016.pt
[2020-08-20 03:10:16,695 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:10:16,717 INFO] number of examples: 4848
[2020-08-20 03:10:26,567 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_5168.pt
[2020-08-20 03:10:50,960 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_5320.pt
[2020-08-20 03:11:15,321 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_5472.pt
[2020-08-20 03:11:31,254 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:11:31,296 INFO] number of examples: 4848
[2020-08-20 03:11:39,719 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_5624.pt
[2020-08-20 03:12:03,977 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_5776.pt
[2020-08-20 03:12:28,519 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_5928.pt
[2020-08-20 03:12:40,141 INFO] Step 6000/10000; acc:  87.76; ppl:  1.28; xent: 0.25; lr: 0.00161; 2487/2002 tok/s;    982 sec
[2020-08-20 03:12:45,662 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:12:45,700 INFO] number of examples: 4848
[2020-08-20 03:12:52,845 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_6080.pt
[2020-08-20 03:13:17,153 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_6232.pt
[2020-08-20 03:13:41,542 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_6384.pt
[2020-08-20 03:14:00,042 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:14:00,085 INFO] number of examples: 4848
[2020-08-20 03:14:05,970 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_6536.pt
[2020-08-20 03:14:31,961 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_6688.pt
[2020-08-20 03:14:57,197 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_6840.pt
[2020-08-20 03:15:16,461 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:15:16,482 INFO] number of examples: 4848
[2020-08-20 03:15:20,966 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_6992.pt
[2020-08-20 03:15:22,877 INFO] Step 7000/10000; acc:  88.05; ppl:  1.27; xent: 0.24; lr: 0.00149; 2460/1980 tok/s;   1145 sec
[2020-08-20 03:15:44,996 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_7144.pt
[2020-08-20 03:16:08,719 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_7296.pt
[2020-08-20 03:16:31,484 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:16:31,527 INFO] number of examples: 4848
[2020-08-20 03:16:34,626 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_7448.pt
[2020-08-20 03:16:58,426 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_7600.pt
[2020-08-20 03:17:22,178 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_7752.pt
[2020-08-20 03:17:44,026 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:17:44,047 INFO] number of examples: 4848
[2020-08-20 03:17:45,912 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_7904.pt
[2020-08-20 03:18:00,930 INFO] Step 8000/10000; acc:  88.42; ppl:  1.26; xent: 0.23; lr: 0.00140; 2534/2040 tok/s;   1303 sec
[2020-08-20 03:18:09,522 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_8056.pt
[2020-08-20 03:18:33,383 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_8208.pt
[2020-08-20 03:18:56,448 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:18:56,495 INFO] number of examples: 4848
[2020-08-20 03:18:57,148 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_8360.pt
[2020-08-20 03:19:20,840 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_8512.pt
[2020-08-20 03:19:47,181 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_8664.pt
[2020-08-20 03:20:10,838 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_8816.pt
[2020-08-20 03:20:13,343 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:20:13,363 INFO] number of examples: 4848
[2020-08-20 03:20:36,221 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_8968.pt
[2020-08-20 03:20:44,489 INFO] Step 9000/10000; acc:  88.57; ppl:  1.25; xent: 0.22; lr: 0.00132; 2448/1972 tok/s;   1467 sec
[2020-08-20 03:21:02,977 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_9120.pt
[2020-08-20 03:21:26,613 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_9272.pt
[2020-08-20 03:21:33,385 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:21:33,432 INFO] number of examples: 4848
[2020-08-20 03:21:54,724 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_9424.pt
[2020-08-20 03:22:18,194 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_9576.pt
[2020-08-20 03:22:41,773 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_9728.pt
[2020-08-20 03:22:45,243 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.train.0.pt
[2020-08-20 03:22:45,264 INFO] number of examples: 4848
[2020-08-20 03:23:05,266 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_9880.pt
[2020-08-20 03:23:24,950 INFO] Step 10000/10000; acc:  88.87; ppl:  1.24; xent: 0.22; lr: 0.00125; 2492/2007 tok/s;   1627 sec
[2020-08-20 03:23:24,951 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_supBiased/.valid.0.pt
[2020-08-20 03:23:24,967 INFO] number of examples: 303
[2020-08-20 03:23:25,484 INFO] Validation perplexity: 1.28821
[2020-08-20 03:23:25,484 INFO] Validation accuracy: 89.8443
[2020-08-20 03:23:25,486 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_supBiased_conv10/toy_model_step_10000.pt
