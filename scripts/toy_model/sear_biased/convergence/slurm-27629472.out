Changed directory to /home/dpk25/MolecularTransformer2/scripts/toy_model/sear_biased/convergence.

JobID: 27629472
======
Time: Wed 19 Aug 22:56:22 BST 2020
Running on master node: gpu-e-40
Current directory: /home/dpk25/MolecularTransformer2/scripts/toy_model/sear_biased/convergence

Nodes allocated:
================
gpu-e-40

numtasks=1, numnodes=1, mpi_tasks_per_node=1 (OMP_NUM_THREADS=1)

Executing command:
==================
./train.sh 

[2020-08-19 22:56:29,496 INFO]  * src vocab size = 20
[2020-08-19 22:56:29,496 INFO]  * tgt vocab size = 20
[2020-08-19 22:56:29,496 INFO] Building model...
[2020-08-19 22:56:36,092 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=20, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-19 22:56:36,094 INFO] encoder: 5265920
[2020-08-19 22:56:36,094 INFO] decoder: 6320660
[2020-08-19 22:56:36,094 INFO] * number of parameters: 11586580
[2020-08-19 22:56:36,097 INFO] Starting training on GPU: [0]
[2020-08-19 22:56:36,097 INFO] Start training loop and validate every 10000 steps...
[2020-08-19 22:56:36,098 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 22:56:36,161 INFO] number of examples: 4960
[2020-08-19 22:57:00,703 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_156.pt
[2020-08-19 22:57:25,022 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_312.pt
[2020-08-19 22:57:49,284 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_468.pt
[2020-08-19 22:57:51,311 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 22:57:51,357 INFO] number of examples: 4960
[2020-08-19 22:58:13,604 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_624.pt
[2020-08-19 22:58:38,258 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_780.pt
[2020-08-19 22:59:02,483 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_936.pt
[2020-08-19 22:59:06,254 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 22:59:06,275 INFO] number of examples: 4960
[2020-08-19 22:59:12,721 INFO] Step 1000/10000; acc:  79.72; ppl:  1.59; xent: 0.46; lr: 0.00140; 2548/2056 tok/s;    157 sec
[2020-08-19 22:59:26,732 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_1092.pt
[2020-08-19 22:59:50,989 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_1248.pt
[2020-08-19 23:00:15,276 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_1404.pt
[2020-08-19 23:00:20,958 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:00:21,003 INFO] number of examples: 4960
[2020-08-19 23:00:39,867 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_1560.pt
[2020-08-19 23:01:05,194 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_1716.pt
[2020-08-19 23:01:29,441 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_1872.pt
[2020-08-19 23:01:36,704 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:01:36,728 INFO] number of examples: 4960
[2020-08-19 23:01:49,439 INFO] Step 2000/10000; acc:  84.69; ppl:  1.39; xent: 0.33; lr: 0.00279; 2546/2054 tok/s;    313 sec
[2020-08-19 23:01:53,723 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_2028.pt
[2020-08-19 23:02:18,147 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_2184.pt
[2020-08-19 23:02:42,397 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_2340.pt
[2020-08-19 23:02:51,297 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:02:51,344 INFO] number of examples: 4960
[2020-08-19 23:03:06,622 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_2496.pt
[2020-08-19 23:03:30,742 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_2652.pt
[2020-08-19 23:03:55,810 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_2808.pt
[2020-08-19 23:04:06,368 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:04:06,389 INFO] number of examples: 4960
[2020-08-19 23:04:20,036 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_2964.pt
[2020-08-19 23:04:25,851 INFO] Step 3000/10000; acc:  84.83; ppl:  1.38; xent: 0.32; lr: 0.00228; 2551/2057 tok/s;    470 sec
[2020-08-19 23:04:44,196 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_3120.pt
[2020-08-19 23:05:08,580 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_3276.pt
[2020-08-19 23:05:20,806 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:05:20,853 INFO] number of examples: 4960
[2020-08-19 23:05:32,843 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_3432.pt
[2020-08-19 23:05:57,098 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_3588.pt
[2020-08-19 23:06:21,368 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_3744.pt
[2020-08-19 23:06:35,564 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:06:35,585 INFO] number of examples: 4960
[2020-08-19 23:06:45,780 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_3900.pt
[2020-08-19 23:07:01,395 INFO] Step 4000/10000; acc:  86.76; ppl:  1.32; xent: 0.28; lr: 0.00198; 2565/2069 tok/s;    625 sec
[2020-08-19 23:07:09,984 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_4056.pt
[2020-08-19 23:07:34,218 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_4212.pt
[2020-08-19 23:07:49,937 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:07:49,984 INFO] number of examples: 4960
[2020-08-19 23:07:58,380 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_4368.pt
[2020-08-19 23:08:22,582 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_4524.pt
[2020-08-19 23:08:46,877 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_4680.pt
[2020-08-19 23:09:04,384 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:09:04,406 INFO] number of examples: 4960
[2020-08-19 23:09:11,160 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_4836.pt
[2020-08-19 23:09:35,303 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_4992.pt
[2020-08-19 23:09:36,823 INFO] Step 5000/10000; acc:  87.10; ppl:  1.31; xent: 0.27; lr: 0.00177; 2569/2073 tok/s;    781 sec
[2020-08-19 23:09:59,316 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_5148.pt
[2020-08-19 23:10:18,633 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:10:18,684 INFO] number of examples: 4960
[2020-08-19 23:10:23,778 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_5304.pt
[2020-08-19 23:10:48,642 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_5460.pt
[2020-08-19 23:11:12,785 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_5616.pt
[2020-08-19 23:11:33,809 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:11:33,830 INFO] number of examples: 4960
[2020-08-19 23:11:37,081 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_5772.pt
[2020-08-19 23:12:02,046 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_5928.pt
[2020-08-19 23:12:13,305 INFO] Step 6000/10000; acc:  87.72; ppl:  1.28; xent: 0.25; lr: 0.00161; 2549/2057 tok/s;    937 sec
[2020-08-19 23:12:26,131 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_6084.pt
[2020-08-19 23:12:48,922 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:12:48,944 INFO] number of examples: 4960
[2020-08-19 23:12:50,551 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_6240.pt
[2020-08-19 23:13:14,710 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_6396.pt
[2020-08-19 23:13:38,907 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_6552.pt
[2020-08-19 23:14:02,995 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_6708.pt
[2020-08-19 23:14:03,481 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:14:03,504 INFO] number of examples: 4960
[2020-08-19 23:14:27,731 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_6864.pt
[2020-08-19 23:14:49,154 INFO] Step 7000/10000; acc:  87.89; ppl:  1.28; xent: 0.25; lr: 0.00149; 2558/2064 tok/s;   1093 sec
[2020-08-19 23:14:52,268 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_7020.pt
[2020-08-19 23:15:16,915 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_7176.pt
[2020-08-19 23:15:19,146 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:15:19,168 INFO] number of examples: 4960
[2020-08-19 23:15:41,450 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_7332.pt
[2020-08-19 23:16:05,895 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_7488.pt
[2020-08-19 23:16:30,238 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_7644.pt
[2020-08-19 23:16:34,404 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:16:34,425 INFO] number of examples: 4960
[2020-08-19 23:16:54,786 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_7800.pt
[2020-08-19 23:17:19,150 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_7956.pt
[2020-08-19 23:17:26,276 INFO] Step 8000/10000; acc:  88.89; ppl:  1.25; xent: 0.22; lr: 0.00140; 2538/2048 tok/s;   1250 sec
[2020-08-19 23:17:43,487 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_8112.pt
[2020-08-19 23:17:49,180 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:17:49,201 INFO] number of examples: 4960
[2020-08-19 23:18:07,829 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_8268.pt
[2020-08-19 23:18:32,143 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_8424.pt
[2020-08-19 23:18:56,564 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_8580.pt
[2020-08-19 23:19:03,976 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:19:04,019 INFO] number of examples: 4960
[2020-08-19 23:19:20,960 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_8736.pt
[2020-08-19 23:19:45,377 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_8892.pt
[2020-08-19 23:20:02,295 INFO] Step 9000/10000; acc:  88.92; ppl:  1.25; xent: 0.22; lr: 0.00132; 2558/2064 tok/s;   1406 sec
[2020-08-19 23:20:09,691 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_9048.pt
[2020-08-19 23:20:18,731 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:20:18,758 INFO] number of examples: 4960
[2020-08-19 23:20:34,004 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_9204.pt
[2020-08-19 23:20:58,427 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_9360.pt
[2020-08-19 23:21:22,763 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_9516.pt
[2020-08-19 23:21:33,712 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:21:33,755 INFO] number of examples: 4960
[2020-08-19 23:21:47,151 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_9672.pt
[2020-08-19 23:22:11,505 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_9828.pt
[2020-08-19 23:22:35,887 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_9984.pt
[2020-08-19 23:22:38,638 INFO] Step 10000/10000; acc:  89.49; ppl:  1.23; xent: 0.21; lr: 0.00125; 2551/2058 tok/s;   1563 sec
[2020-08-19 23:22:38,638 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.valid.0.pt
[2020-08-19 23:22:38,670 INFO] number of examples: 310
[2020-08-19 23:22:39,202 INFO] Validation perplexity: 1.25856
[2020-08-19 23:22:39,202 INFO] Validation accuracy: 90.7491
[2020-08-19 23:22:39,203 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv1/toy_model_step_10000.pt
[2020-08-19 23:22:40,618 INFO]  * src vocab size = 20
[2020-08-19 23:22:40,618 INFO]  * tgt vocab size = 20
[2020-08-19 23:22:40,618 INFO] Building model...
[2020-08-19 23:22:42,784 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=20, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-19 23:22:42,786 INFO] encoder: 5265920
[2020-08-19 23:22:42,786 INFO] decoder: 6320660
[2020-08-19 23:22:42,786 INFO] * number of parameters: 11586580
[2020-08-19 23:22:42,797 INFO] Starting training on GPU: [0]
[2020-08-19 23:22:42,797 INFO] Start training loop and validate every 10000 steps...
[2020-08-19 23:22:42,798 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:22:42,823 INFO] number of examples: 4960
[2020-08-19 23:23:06,576 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_156.pt
[2020-08-19 23:23:30,665 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_312.pt
[2020-08-19 23:23:54,632 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_468.pt
[2020-08-19 23:23:56,626 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:23:56,671 INFO] number of examples: 4960
[2020-08-19 23:24:18,531 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_624.pt
[2020-08-19 23:24:42,347 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_780.pt
[2020-08-19 23:25:06,258 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_936.pt
[2020-08-19 23:25:10,009 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:25:10,031 INFO] number of examples: 4960
[2020-08-19 23:25:16,400 INFO] Step 1000/10000; acc:  79.43; ppl:  1.60; xent: 0.47; lr: 0.00140; 2597/2095 tok/s;    154 sec
[2020-08-19 23:25:30,311 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_1092.pt
[2020-08-19 23:25:54,164 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_1248.pt
[2020-08-19 23:26:18,102 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_1404.pt
[2020-08-19 23:26:23,378 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:26:23,424 INFO] number of examples: 4960
[2020-08-19 23:26:41,876 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_1560.pt
[2020-08-19 23:27:05,341 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_1716.pt
[2020-08-19 23:27:30,224 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_1872.pt
[2020-08-19 23:27:37,248 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:27:37,269 INFO] number of examples: 4960
[2020-08-19 23:27:49,660 INFO] Step 2000/10000; acc:  85.37; ppl:  1.37; xent: 0.31; lr: 0.00279; 2602/2100 tok/s;    307 sec
[2020-08-19 23:27:53,832 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_2028.pt
[2020-08-19 23:28:17,526 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_2184.pt
[2020-08-19 23:28:41,105 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_2340.pt
[2020-08-19 23:28:49,801 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:28:49,848 INFO] number of examples: 4960
[2020-08-19 23:29:04,786 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_2496.pt
[2020-08-19 23:29:28,327 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_2652.pt
[2020-08-19 23:29:51,862 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_2808.pt
[2020-08-19 23:30:02,088 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:30:02,111 INFO] number of examples: 4960
[2020-08-19 23:30:15,395 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_2964.pt
[2020-08-19 23:30:21,046 INFO] Step 3000/10000; acc:  85.07; ppl:  1.37; xent: 0.32; lr: 0.00228; 2635/2126 tok/s;    458 sec
[2020-08-19 23:30:38,944 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_3120.pt
[2020-08-19 23:31:02,460 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_3276.pt
[2020-08-19 23:31:14,447 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:31:14,494 INFO] number of examples: 4960
[2020-08-19 23:31:26,072 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_3432.pt
[2020-08-19 23:31:49,628 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_3588.pt
[2020-08-19 23:32:13,089 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_3744.pt
[2020-08-19 23:32:26,860 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:32:26,882 INFO] number of examples: 4960
[2020-08-19 23:32:36,691 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_3900.pt
[2020-08-19 23:32:51,929 INFO] Step 4000/10000; acc:  86.22; ppl:  1.33; xent: 0.29; lr: 0.00198; 2645/2134 tok/s;    609 sec
[2020-08-19 23:33:00,250 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_4056.pt
[2020-08-19 23:33:23,621 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_4212.pt
[2020-08-19 23:33:38,966 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:33:39,016 INFO] number of examples: 4960
[2020-08-19 23:33:47,174 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_4368.pt
[2020-08-19 23:34:10,720 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_4524.pt
[2020-08-19 23:34:34,225 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_4680.pt
[2020-08-19 23:34:51,164 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:34:51,186 INFO] number of examples: 4960
[2020-08-19 23:34:57,774 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_4836.pt
[2020-08-19 23:35:21,243 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_4992.pt
[2020-08-19 23:35:22,752 INFO] Step 5000/10000; acc:  86.80; ppl:  1.32; xent: 0.27; lr: 0.00177; 2645/2135 tok/s;    760 sec
[2020-08-19 23:35:44,791 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_5148.pt
[2020-08-19 23:36:03,419 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:36:03,470 INFO] number of examples: 4960
[2020-08-19 23:36:08,378 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_5304.pt
[2020-08-19 23:36:32,210 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_5460.pt
[2020-08-19 23:36:55,774 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_5616.pt
[2020-08-19 23:37:16,151 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:37:16,174 INFO] number of examples: 4960
[2020-08-19 23:37:19,321 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_5772.pt
[2020-08-19 23:37:42,864 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_5928.pt
[2020-08-19 23:37:53,774 INFO] Step 6000/10000; acc:  87.21; ppl:  1.30; xent: 0.26; lr: 0.00161; 2642/2132 tok/s;    911 sec
[2020-08-19 23:38:06,141 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_6084.pt
[2020-08-19 23:38:28,038 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:38:28,060 INFO] number of examples: 4960
[2020-08-19 23:38:29,599 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_6240.pt
[2020-08-19 23:38:52,849 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_6396.pt
[2020-08-19 23:39:15,987 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_6552.pt
[2020-08-19 23:39:39,526 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_6708.pt
[2020-08-19 23:39:39,984 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:39:40,005 INFO] number of examples: 4960
[2020-08-19 23:40:02,791 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_6864.pt
[2020-08-19 23:40:23,124 INFO] Step 7000/10000; acc:  87.08; ppl:  1.31; xent: 0.27; lr: 0.00149; 2670/2155 tok/s;   1060 sec
[2020-08-19 23:40:26,105 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_7020.pt
[2020-08-19 23:40:49,370 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_7176.pt
[2020-08-19 23:40:51,461 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:40:51,483 INFO] number of examples: 4960
[2020-08-19 23:41:12,795 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_7332.pt
[2020-08-19 23:41:36,110 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_7488.pt
[2020-08-19 23:41:59,396 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_7644.pt
[2020-08-19 23:42:03,284 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:42:03,305 INFO] number of examples: 4960
[2020-08-19 23:42:22,826 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_7800.pt
[2020-08-19 23:42:46,163 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_7956.pt
[2020-08-19 23:42:52,942 INFO] Step 8000/10000; acc:  86.00; ppl:  1.34; xent: 0.29; lr: 0.00140; 2664/2149 tok/s;   1210 sec
[2020-08-19 23:43:09,511 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_8112.pt
[2020-08-19 23:43:14,925 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:43:14,946 INFO] number of examples: 4960
[2020-08-19 23:43:32,777 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_8268.pt
[2020-08-19 23:43:56,355 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_8424.pt
[2020-08-19 23:44:19,825 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_8580.pt
[2020-08-19 23:44:26,910 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:44:26,954 INFO] number of examples: 4960
[2020-08-19 23:44:43,181 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_8736.pt
[2020-08-19 23:45:06,519 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_8892.pt
[2020-08-19 23:45:22,744 INFO] Step 9000/10000; acc:  86.80; ppl:  1.31; xent: 0.27; lr: 0.00132; 2661/2147 tok/s;   1360 sec
[2020-08-19 23:45:29,790 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_9048.pt
[2020-08-19 23:45:38,523 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:45:38,545 INFO] number of examples: 4960
[2020-08-19 23:45:53,127 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_9204.pt
[2020-08-19 23:46:16,506 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_9360.pt
[2020-08-19 23:46:39,687 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_9516.pt
[2020-08-19 23:46:50,229 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:46:50,272 INFO] number of examples: 4960
[2020-08-19 23:47:03,089 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_9672.pt
[2020-08-19 23:47:26,414 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_9828.pt
[2020-08-19 23:47:49,724 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_9984.pt
[2020-08-19 23:47:52,350 INFO] Step 10000/10000; acc:  87.40; ppl:  1.29; xent: 0.26; lr: 0.00125; 2666/2151 tok/s;   1510 sec
[2020-08-19 23:47:52,351 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.valid.0.pt
[2020-08-19 23:47:52,385 INFO] number of examples: 310
[2020-08-19 23:47:52,912 INFO] Validation perplexity: 1.31275
[2020-08-19 23:47:52,912 INFO] Validation accuracy: 89.2982
[2020-08-19 23:47:52,914 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv2/toy_model_step_10000.pt
[2020-08-19 23:47:54,366 INFO]  * src vocab size = 20
[2020-08-19 23:47:54,366 INFO]  * tgt vocab size = 20
[2020-08-19 23:47:54,366 INFO] Building model...
[2020-08-19 23:47:56,499 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=20, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-19 23:47:56,501 INFO] encoder: 5265920
[2020-08-19 23:47:56,501 INFO] decoder: 6320660
[2020-08-19 23:47:56,501 INFO] * number of parameters: 11586580
[2020-08-19 23:47:56,505 INFO] Starting training on GPU: [0]
[2020-08-19 23:47:56,505 INFO] Start training loop and validate every 10000 steps...
[2020-08-19 23:47:56,505 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:47:56,530 INFO] number of examples: 4960
[2020-08-19 23:48:20,886 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_156.pt
[2020-08-19 23:48:45,396 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_312.pt
[2020-08-19 23:49:09,922 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_468.pt
[2020-08-19 23:49:11,916 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:49:11,962 INFO] number of examples: 4960
[2020-08-19 23:49:34,535 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_624.pt
[2020-08-19 23:49:59,003 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_780.pt
[2020-08-19 23:50:23,528 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_936.pt
[2020-08-19 23:50:27,253 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:50:27,273 INFO] number of examples: 4960
[2020-08-19 23:50:33,817 INFO] Step 1000/10000; acc:  79.60; ppl:  1.59; xent: 0.47; lr: 0.00140; 2536/2045 tok/s;    157 sec
[2020-08-19 23:50:48,077 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_1092.pt
[2020-08-19 23:51:12,747 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_1248.pt
[2020-08-19 23:51:37,240 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_1404.pt
[2020-08-19 23:51:42,769 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:51:42,814 INFO] number of examples: 4960
[2020-08-19 23:52:01,877 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_1560.pt
[2020-08-19 23:52:26,418 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_1716.pt
[2020-08-19 23:52:51,006 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_1872.pt
[2020-08-19 23:52:58,257 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:52:58,279 INFO] number of examples: 4960
[2020-08-19 23:53:11,156 INFO] Step 2000/10000; acc:  85.24; ppl:  1.37; xent: 0.32; lr: 0.00279; 2534/2045 tok/s;    315 sec
[2020-08-19 23:53:15,498 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_2028.pt
[2020-08-19 23:53:39,953 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_2184.pt
[2020-08-19 23:54:04,529 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_2340.pt
[2020-08-19 23:54:13,454 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:54:13,502 INFO] number of examples: 4960
[2020-08-19 23:54:28,992 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_2496.pt
[2020-08-19 23:54:53,509 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_2652.pt
[2020-08-19 23:55:18,052 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_2808.pt
[2020-08-19 23:55:28,722 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:55:28,744 INFO] number of examples: 4960
[2020-08-19 23:55:42,524 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_2964.pt
[2020-08-19 23:55:48,449 INFO] Step 3000/10000; acc:  85.36; ppl:  1.37; xent: 0.31; lr: 0.00228; 2538/2048 tok/s;    472 sec
[2020-08-19 23:56:07,096 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_3120.pt
[2020-08-19 23:56:31,576 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_3276.pt
[2020-08-19 23:56:44,029 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:56:44,078 INFO] number of examples: 4960
[2020-08-19 23:56:56,180 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_3432.pt
[2020-08-19 23:57:20,694 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_3588.pt
[2020-08-19 23:57:45,217 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_3744.pt
[2020-08-19 23:57:59,467 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:57:59,489 INFO] number of examples: 4960
[2020-08-19 23:58:09,762 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_3900.pt
[2020-08-19 23:58:25,608 INFO] Step 4000/10000; acc:  85.34; ppl:  1.36; xent: 0.31; lr: 0.00198; 2538/2048 tok/s;    629 sec
[2020-08-19 23:58:34,322 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_4056.pt
[2020-08-19 23:58:58,926 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_4212.pt
[2020-08-19 23:59:14,930 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-19 23:59:14,979 INFO] number of examples: 4960
[2020-08-19 23:59:23,555 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_4368.pt
[2020-08-19 23:59:48,150 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_4524.pt
[2020-08-20 00:00:12,739 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_4680.pt
[2020-08-20 00:00:30,541 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:00:30,563 INFO] number of examples: 4960
[2020-08-20 00:00:37,424 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_4836.pt
[2020-08-20 00:01:01,926 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_4992.pt
[2020-08-20 00:01:03,471 INFO] Step 5000/10000; acc:  85.45; ppl:  1.35; xent: 0.30; lr: 0.00177; 2527/2039 tok/s;    787 sec
[2020-08-20 00:01:26,527 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_5148.pt
[2020-08-20 00:01:46,004 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:01:46,055 INFO] number of examples: 4960
[2020-08-20 00:01:51,210 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_5304.pt
[2020-08-20 00:02:15,833 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_5460.pt
[2020-08-20 00:02:40,267 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_5616.pt
[2020-08-20 00:03:01,517 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:03:01,538 INFO] number of examples: 4960
[2020-08-20 00:03:04,821 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_5772.pt
[2020-08-20 00:03:29,261 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_5928.pt
[2020-08-20 00:03:40,663 INFO] Step 6000/10000; acc:  85.99; ppl:  1.33; xent: 0.28; lr: 0.00161; 2538/2049 tok/s;    944 sec
[2020-08-20 00:03:53,608 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_6084.pt
[2020-08-20 00:04:16,326 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:04:16,350 INFO] number of examples: 4960
[2020-08-20 00:04:17,951 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_6240.pt
[2020-08-20 00:04:42,226 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_6396.pt
[2020-08-20 00:05:06,468 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_6552.pt
[2020-08-20 00:05:30,778 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_6708.pt
[2020-08-20 00:05:31,236 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:05:31,257 INFO] number of examples: 4960
[2020-08-20 00:05:54,991 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_6864.pt
[2020-08-20 00:06:16,114 INFO] Step 7000/10000; acc:  86.23; ppl:  1.32; xent: 0.28; lr: 0.00149; 2567/2071 tok/s;   1100 sec
[2020-08-20 00:06:19,199 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_7020.pt
[2020-08-20 00:06:43,267 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_7176.pt
[2020-08-20 00:06:45,477 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:06:45,498 INFO] number of examples: 4960
[2020-08-20 00:07:07,655 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_7332.pt
[2020-08-20 00:07:31,952 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_7488.pt
[2020-08-20 00:07:56,174 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_7644.pt
[2020-08-20 00:08:00,197 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:08:00,222 INFO] number of examples: 4960
[2020-08-20 00:08:20,503 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_7800.pt
[2020-08-20 00:08:44,824 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_7956.pt
[2020-08-20 00:08:51,894 INFO] Step 8000/10000; acc:  86.45; ppl:  1.31; xent: 0.27; lr: 0.00140; 2561/2066 tok/s;   1255 sec
[2020-08-20 00:09:09,075 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_8112.pt
[2020-08-20 00:09:14,742 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:09:14,764 INFO] number of examples: 4960
[2020-08-20 00:09:33,402 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_8268.pt
[2020-08-20 00:09:57,684 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_8424.pt
[2020-08-20 00:10:21,763 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_8580.pt
[2020-08-20 00:10:29,044 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:10:29,087 INFO] number of examples: 4960
[2020-08-20 00:10:45,932 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_8736.pt
[2020-08-20 00:11:10,204 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_8892.pt
[2020-08-20 00:11:27,024 INFO] Step 9000/10000; acc:  87.01; ppl:  1.30; xent: 0.26; lr: 0.00132; 2571/2075 tok/s;   1411 sec
[2020-08-20 00:11:34,410 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_9048.pt
[2020-08-20 00:11:43,434 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:11:43,456 INFO] number of examples: 4960
[2020-08-20 00:11:58,645 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_9204.pt
[2020-08-20 00:12:22,848 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_9360.pt
[2020-08-20 00:12:46,979 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_9516.pt
[2020-08-20 00:12:57,851 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:12:57,903 INFO] number of examples: 4960
[2020-08-20 00:13:11,254 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_9672.pt
[2020-08-20 00:13:35,449 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_9828.pt
[2020-08-20 00:13:59,584 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_9984.pt
[2020-08-20 00:14:02,319 INFO] Step 10000/10000; acc:  87.09; ppl:  1.29; xent: 0.26; lr: 0.00125; 2569/2072 tok/s;   1566 sec
[2020-08-20 00:14:02,320 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.valid.0.pt
[2020-08-20 00:14:02,322 INFO] number of examples: 310
[2020-08-20 00:14:02,866 INFO] Validation perplexity: 1.34889
[2020-08-20 00:14:02,866 INFO] Validation accuracy: 87.3739
[2020-08-20 00:14:02,868 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv3/toy_model_step_10000.pt
[2020-08-20 00:14:04,273 INFO]  * src vocab size = 20
[2020-08-20 00:14:04,273 INFO]  * tgt vocab size = 20
[2020-08-20 00:14:04,273 INFO] Building model...
[2020-08-20 00:14:06,400 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=20, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 00:14:06,402 INFO] encoder: 5265920
[2020-08-20 00:14:06,402 INFO] decoder: 6320660
[2020-08-20 00:14:06,402 INFO] * number of parameters: 11586580
[2020-08-20 00:14:06,407 INFO] Starting training on GPU: [0]
[2020-08-20 00:14:06,407 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 00:14:06,407 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:14:06,432 INFO] number of examples: 4960
[2020-08-20 00:14:30,220 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_156.pt
[2020-08-20 00:14:54,228 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_312.pt
[2020-08-20 00:15:18,155 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_468.pt
[2020-08-20 00:15:20,227 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:15:20,274 INFO] number of examples: 4960
[2020-08-20 00:15:42,271 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_624.pt
[2020-08-20 00:16:06,145 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_780.pt
[2020-08-20 00:16:29,913 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_936.pt
[2020-08-20 00:16:33,512 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:16:33,533 INFO] number of examples: 4960
[2020-08-20 00:16:39,854 INFO] Step 1000/10000; acc:  79.32; ppl:  1.60; xent: 0.47; lr: 0.00140; 2600/2099 tok/s;    153 sec
[2020-08-20 00:16:53,628 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_1092.pt
[2020-08-20 00:17:17,169 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_1248.pt
[2020-08-20 00:17:40,672 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_1404.pt
[2020-08-20 00:17:45,943 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:17:45,986 INFO] number of examples: 4960
[2020-08-20 00:18:04,381 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_1560.pt
[2020-08-20 00:18:28,071 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_1716.pt
[2020-08-20 00:18:51,689 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_1872.pt
[2020-08-20 00:18:58,642 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:18:58,662 INFO] number of examples: 4960
[2020-08-20 00:19:11,093 INFO] Step 2000/10000; acc:  84.99; ppl:  1.38; xent: 0.32; lr: 0.00279; 2639/2129 tok/s;    305 sec
[2020-08-20 00:19:15,313 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_2028.pt
[2020-08-20 00:19:38,878 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_2184.pt
[2020-08-20 00:20:02,418 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_2340.pt
[2020-08-20 00:20:11,280 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:20:11,327 INFO] number of examples: 4960
[2020-08-20 00:20:26,218 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_2496.pt
[2020-08-20 00:20:49,732 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_2652.pt
[2020-08-20 00:21:13,262 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_2808.pt
[2020-08-20 00:21:23,652 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:21:23,673 INFO] number of examples: 4960
[2020-08-20 00:21:36,986 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_2964.pt
[2020-08-20 00:21:42,717 INFO] Step 3000/10000; acc:  85.02; ppl:  1.37; xent: 0.32; lr: 0.00228; 2634/2125 tok/s;    456 sec
[2020-08-20 00:22:00,651 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_3120.pt
[2020-08-20 00:22:24,256 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_3276.pt
[2020-08-20 00:22:36,204 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:22:36,252 INFO] number of examples: 4960
[2020-08-20 00:22:47,922 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_3432.pt
[2020-08-20 00:23:11,504 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_3588.pt
[2020-08-20 00:23:35,062 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_3744.pt
[2020-08-20 00:23:49,553 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:23:49,574 INFO] number of examples: 4960
[2020-08-20 00:23:59,425 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_3900.pt
[2020-08-20 00:24:14,673 INFO] Step 4000/10000; acc:  85.40; ppl:  1.36; xent: 0.30; lr: 0.00198; 2626/2118 tok/s;    608 sec
[2020-08-20 00:24:23,070 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_4056.pt
[2020-08-20 00:24:46,994 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_4212.pt
[2020-08-20 00:25:02,467 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:25:02,516 INFO] number of examples: 4960
[2020-08-20 00:25:10,708 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_4368.pt
[2020-08-20 00:25:34,682 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_4524.pt
[2020-08-20 00:25:58,346 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_4680.pt
[2020-08-20 00:26:15,407 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:26:15,428 INFO] number of examples: 4960
[2020-08-20 00:26:22,029 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_4836.pt
[2020-08-20 00:26:45,527 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_4992.pt
[2020-08-20 00:26:47,067 INFO] Step 5000/10000; acc:  85.82; ppl:  1.34; xent: 0.29; lr: 0.00177; 2618/2112 tok/s;    761 sec
[2020-08-20 00:27:09,157 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_5148.pt
[2020-08-20 00:27:27,825 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:27:27,880 INFO] number of examples: 4960
[2020-08-20 00:27:32,828 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_5304.pt
[2020-08-20 00:27:56,304 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_5460.pt
[2020-08-20 00:28:19,896 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_5616.pt
[2020-08-20 00:28:40,229 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:28:40,251 INFO] number of examples: 4960
[2020-08-20 00:28:43,385 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_5772.pt
[2020-08-20 00:29:06,858 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_5928.pt
[2020-08-20 00:29:17,999 INFO] Step 6000/10000; acc:  86.17; ppl:  1.33; xent: 0.28; lr: 0.00161; 2643/2133 tok/s;    912 sec
[2020-08-20 00:29:30,413 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_6084.pt
[2020-08-20 00:29:52,379 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:29:52,401 INFO] number of examples: 4960
[2020-08-20 00:29:53,952 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_6240.pt
[2020-08-20 00:30:17,301 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_6396.pt
[2020-08-20 00:30:40,693 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_6552.pt
[2020-08-20 00:31:04,028 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_6708.pt
[2020-08-20 00:31:04,505 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:31:04,527 INFO] number of examples: 4960
[2020-08-20 00:31:27,495 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_6864.pt
[2020-08-20 00:31:47,964 INFO] Step 7000/10000; acc:  86.25; ppl:  1.32; xent: 0.28; lr: 0.00149; 2660/2146 tok/s;   1062 sec
[2020-08-20 00:31:50,921 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_7020.pt
[2020-08-20 00:32:14,240 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_7176.pt
[2020-08-20 00:32:16,319 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:32:16,341 INFO] number of examples: 4960
[2020-08-20 00:32:37,660 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_7332.pt
[2020-08-20 00:33:01,061 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_7488.pt
[2020-08-20 00:33:24,377 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_7644.pt
[2020-08-20 00:33:28,292 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:33:28,314 INFO] number of examples: 4960
[2020-08-20 00:33:47,919 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_7800.pt
[2020-08-20 00:34:11,348 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_7956.pt
[2020-08-20 00:34:18,127 INFO] Step 8000/10000; acc:  86.83; ppl:  1.30; xent: 0.27; lr: 0.00140; 2657/2144 tok/s;   1212 sec
[2020-08-20 00:34:34,726 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_8112.pt
[2020-08-20 00:34:40,186 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:34:40,209 INFO] number of examples: 4960
[2020-08-20 00:34:58,178 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_8268.pt
[2020-08-20 00:35:21,624 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_8424.pt
[2020-08-20 00:35:45,109 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_8580.pt
[2020-08-20 00:35:52,281 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:35:52,365 INFO] number of examples: 4960
[2020-08-20 00:36:08,631 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_8736.pt
[2020-08-20 00:36:32,680 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_8892.pt
[2020-08-20 00:36:48,950 INFO] Step 9000/10000; acc:  86.46; ppl:  1.32; xent: 0.28; lr: 0.00132; 2645/2134 tok/s;   1363 sec
[2020-08-20 00:36:56,036 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_9048.pt
[2020-08-20 00:37:04,739 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:37:04,762 INFO] number of examples: 4960
[2020-08-20 00:37:19,485 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_9204.pt
[2020-08-20 00:37:42,841 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_9360.pt
[2020-08-20 00:38:06,161 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_9516.pt
[2020-08-20 00:38:16,654 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:38:16,697 INFO] number of examples: 4960
[2020-08-20 00:38:29,596 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_9672.pt
[2020-08-20 00:38:53,076 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_9828.pt
[2020-08-20 00:39:16,460 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_9984.pt
[2020-08-20 00:39:19,178 INFO] Step 10000/10000; acc:  87.37; ppl:  1.29; xent: 0.25; lr: 0.00125; 2656/2143 tok/s;   1513 sec
[2020-08-20 00:39:19,179 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.valid.0.pt
[2020-08-20 00:39:19,198 INFO] number of examples: 310
[2020-08-20 00:39:19,716 INFO] Validation perplexity: 1.33526
[2020-08-20 00:39:19,716 INFO] Validation accuracy: 88.156
[2020-08-20 00:39:19,717 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv4/toy_model_step_10000.pt
[2020-08-20 00:39:21,180 INFO]  * src vocab size = 20
[2020-08-20 00:39:21,181 INFO]  * tgt vocab size = 20
[2020-08-20 00:39:21,181 INFO] Building model...
[2020-08-20 00:39:23,295 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=20, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 00:39:23,297 INFO] encoder: 5265920
[2020-08-20 00:39:23,297 INFO] decoder: 6320660
[2020-08-20 00:39:23,297 INFO] * number of parameters: 11586580
[2020-08-20 00:39:23,313 INFO] Starting training on GPU: [0]
[2020-08-20 00:39:23,313 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 00:39:23,313 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:39:23,339 INFO] number of examples: 4960
[2020-08-20 00:39:47,300 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_156.pt
[2020-08-20 00:40:11,428 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_312.pt
[2020-08-20 00:40:35,448 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_468.pt
[2020-08-20 00:40:37,901 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:40:37,946 INFO] number of examples: 4960
[2020-08-20 00:41:00,049 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_624.pt
[2020-08-20 00:41:24,185 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_780.pt
[2020-08-20 00:41:48,258 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_936.pt
[2020-08-20 00:41:52,669 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:41:52,691 INFO] number of examples: 4960
[2020-08-20 00:41:59,140 INFO] Step 1000/10000; acc:  79.42; ppl:  1.61; xent: 0.48; lr: 0.00140; 2561/2067 tok/s;    156 sec
[2020-08-20 00:42:13,205 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_1092.pt
[2020-08-20 00:42:37,414 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_1248.pt
[2020-08-20 00:43:01,486 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_1404.pt
[2020-08-20 00:43:06,776 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:43:06,823 INFO] number of examples: 4960
[2020-08-20 00:43:25,537 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_1560.pt
[2020-08-20 00:43:49,560 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_1716.pt
[2020-08-20 00:44:13,611 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_1872.pt
[2020-08-20 00:44:20,806 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:44:20,827 INFO] number of examples: 4960
[2020-08-20 00:44:33,503 INFO] Step 2000/10000; acc:  85.13; ppl:  1.38; xent: 0.32; lr: 0.00279; 2583/2085 tok/s;    310 sec
[2020-08-20 00:44:37,765 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_2028.pt
[2020-08-20 00:45:01,823 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_2184.pt
[2020-08-20 00:45:25,778 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_2340.pt
[2020-08-20 00:45:34,633 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:45:34,680 INFO] number of examples: 4960
[2020-08-20 00:45:49,963 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_2496.pt
[2020-08-20 00:46:14,014 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_2652.pt
[2020-08-20 00:46:38,075 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_2808.pt
[2020-08-20 00:46:48,681 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:46:48,703 INFO] number of examples: 4960
[2020-08-20 00:47:02,290 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_2964.pt
[2020-08-20 00:47:08,762 INFO] Step 3000/10000; acc:  85.27; ppl:  1.37; xent: 0.31; lr: 0.00228; 2570/2074 tok/s;    465 sec
[2020-08-20 00:47:27,124 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_3120.pt
[2020-08-20 00:47:51,138 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_3276.pt
[2020-08-20 00:48:03,335 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:48:03,383 INFO] number of examples: 4960
[2020-08-20 00:48:15,314 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_3432.pt
[2020-08-20 00:48:39,330 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_3588.pt
[2020-08-20 00:49:03,473 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_3744.pt
[2020-08-20 00:49:17,567 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:49:17,590 INFO] number of examples: 4960
[2020-08-20 00:49:27,684 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_3900.pt
[2020-08-20 00:49:43,247 INFO] Step 4000/10000; acc:  86.27; ppl:  1.33; xent: 0.29; lr: 0.00198; 2583/2084 tok/s;    620 sec
[2020-08-20 00:49:51,806 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_4056.pt
[2020-08-20 00:50:15,793 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_4212.pt
[2020-08-20 00:50:31,474 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:50:31,523 INFO] number of examples: 4960
[2020-08-20 00:50:39,933 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_4368.pt
[2020-08-20 00:51:03,994 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_4524.pt
[2020-08-20 00:51:28,012 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_4680.pt
[2020-08-20 00:51:45,378 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:51:45,400 INFO] number of examples: 4960
[2020-08-20 00:51:52,138 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_4836.pt
[2020-08-20 00:52:16,247 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_4992.pt
[2020-08-20 00:52:17,783 INFO] Step 5000/10000; acc:  86.68; ppl:  1.32; xent: 0.28; lr: 0.00177; 2581/2082 tok/s;    774 sec
[2020-08-20 00:52:40,348 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_5148.pt
[2020-08-20 00:52:59,369 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:52:59,420 INFO] number of examples: 4960
[2020-08-20 00:53:04,489 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_5304.pt
[2020-08-20 00:53:28,591 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_5460.pt
[2020-08-20 00:53:52,610 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_5616.pt
[2020-08-20 00:54:13,343 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:54:13,365 INFO] number of examples: 4960
[2020-08-20 00:54:16,575 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_5772.pt
[2020-08-20 00:54:40,504 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_5928.pt
[2020-08-20 00:54:51,743 INFO] Step 6000/10000; acc:  86.02; ppl:  1.34; xent: 0.29; lr: 0.00161; 2590/2089 tok/s;    928 sec
[2020-08-20 00:55:04,537 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_6084.pt
[2020-08-20 00:55:26,843 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:55:26,865 INFO] number of examples: 4960
[2020-08-20 00:55:28,437 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_6240.pt
[2020-08-20 00:55:52,262 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_6396.pt
[2020-08-20 00:56:15,998 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_6552.pt
[2020-08-20 00:56:39,671 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_6708.pt
[2020-08-20 00:56:40,268 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:56:40,289 INFO] number of examples: 4960
[2020-08-20 00:57:03,602 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_6864.pt
[2020-08-20 00:57:24,332 INFO] Step 7000/10000; acc:  87.18; ppl:  1.30; xent: 0.26; lr: 0.00149; 2614/2109 tok/s;   1081 sec
[2020-08-20 00:57:27,606 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_7020.pt
[2020-08-20 00:57:51,366 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_7176.pt
[2020-08-20 00:57:53,499 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:57:53,520 INFO] number of examples: 4960
[2020-08-20 00:58:15,210 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_7332.pt
[2020-08-20 00:58:38,997 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_7488.pt
[2020-08-20 00:59:02,687 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_7644.pt
[2020-08-20 00:59:06,682 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 00:59:06,703 INFO] number of examples: 4960
[2020-08-20 00:59:26,618 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_7800.pt
[2020-08-20 00:59:50,329 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_7956.pt
[2020-08-20 00:59:57,307 INFO] Step 8000/10000; acc:  87.51; ppl:  1.29; xent: 0.26; lr: 0.00140; 2613/2108 tok/s;   1234 sec
[2020-08-20 01:00:14,125 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_8112.pt
[2020-08-20 01:00:19,640 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:00:19,663 INFO] number of examples: 4960
[2020-08-20 01:00:37,929 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_8268.pt
[2020-08-20 01:01:01,716 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_8424.pt
[2020-08-20 01:01:25,520 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_8580.pt
[2020-08-20 01:01:32,722 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:01:32,763 INFO] number of examples: 4960
[2020-08-20 01:01:49,286 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_8736.pt
[2020-08-20 01:02:13,019 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_8892.pt
[2020-08-20 01:02:29,551 INFO] Step 9000/10000; acc:  87.73; ppl:  1.28; xent: 0.25; lr: 0.00132; 2621/2115 tok/s;   1386 sec
[2020-08-20 01:02:36,743 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_9048.pt
[2020-08-20 01:02:45,588 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:02:45,610 INFO] number of examples: 4960
[2020-08-20 01:03:00,501 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_9204.pt
[2020-08-20 01:03:24,169 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_9360.pt
[2020-08-20 01:03:47,866 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_9516.pt
[2020-08-20 01:03:58,505 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:03:58,549 INFO] number of examples: 4960
[2020-08-20 01:04:11,704 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_9672.pt
[2020-08-20 01:04:35,483 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_9828.pt
[2020-08-20 01:04:59,190 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_9984.pt
[2020-08-20 01:05:01,894 INFO] Step 10000/10000; acc:  87.80; ppl:  1.28; xent: 0.24; lr: 0.00125; 2619/2112 tok/s;   1539 sec
[2020-08-20 01:05:01,895 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.valid.0.pt
[2020-08-20 01:05:01,914 INFO] number of examples: 310
[2020-08-20 01:05:02,442 INFO] Validation perplexity: 1.31275
[2020-08-20 01:05:02,442 INFO] Validation accuracy: 89.1439
[2020-08-20 01:05:02,444 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv5/toy_model_step_10000.pt
[2020-08-20 01:05:03,823 INFO]  * src vocab size = 20
[2020-08-20 01:05:03,823 INFO]  * tgt vocab size = 20
[2020-08-20 01:05:03,823 INFO] Building model...
[2020-08-20 01:05:05,953 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=20, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 01:05:05,955 INFO] encoder: 5265920
[2020-08-20 01:05:05,955 INFO] decoder: 6320660
[2020-08-20 01:05:05,955 INFO] * number of parameters: 11586580
[2020-08-20 01:05:05,959 INFO] Starting training on GPU: [0]
[2020-08-20 01:05:05,959 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 01:05:05,959 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:05:05,983 INFO] number of examples: 4960
[2020-08-20 01:05:30,325 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_156.pt
[2020-08-20 01:05:54,800 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_312.pt
[2020-08-20 01:06:19,150 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_468.pt
[2020-08-20 01:06:21,192 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:06:21,239 INFO] number of examples: 4960
[2020-08-20 01:06:43,761 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_624.pt
[2020-08-20 01:07:08,226 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_780.pt
[2020-08-20 01:07:32,768 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_936.pt
[2020-08-20 01:07:36,622 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:07:36,643 INFO] number of examples: 4960
[2020-08-20 01:07:43,168 INFO] Step 1000/10000; acc:  79.80; ppl:  1.59; xent: 0.47; lr: 0.00140; 2536/2046 tok/s;    157 sec
[2020-08-20 01:07:57,393 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_1092.pt
[2020-08-20 01:08:21,777 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_1248.pt
[2020-08-20 01:08:46,178 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_1404.pt
[2020-08-20 01:08:51,736 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:08:51,783 INFO] number of examples: 4960
[2020-08-20 01:09:10,900 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_1560.pt
[2020-08-20 01:09:35,442 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_1716.pt
[2020-08-20 01:09:59,855 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_1872.pt
[2020-08-20 01:10:07,057 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:10:07,078 INFO] number of examples: 4960
[2020-08-20 01:10:19,817 INFO] Step 2000/10000; acc:  85.30; ppl:  1.37; xent: 0.32; lr: 0.00279; 2547/2055 tok/s;    314 sec
[2020-08-20 01:10:24,082 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_2028.pt
[2020-08-20 01:10:48,260 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_2184.pt
[2020-08-20 01:11:12,357 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_2340.pt
[2020-08-20 01:11:21,215 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:11:21,261 INFO] number of examples: 4960
[2020-08-20 01:11:36,572 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_2496.pt
[2020-08-20 01:12:00,886 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_2652.pt
[2020-08-20 01:12:25,740 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_2808.pt
[2020-08-20 01:12:36,271 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:12:36,294 INFO] number of examples: 4960
[2020-08-20 01:12:49,889 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_2964.pt
[2020-08-20 01:12:55,812 INFO] Step 3000/10000; acc:  85.47; ppl:  1.36; xent: 0.31; lr: 0.00228; 2559/2064 tok/s;    470 sec
[2020-08-20 01:13:14,180 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_3120.pt
[2020-08-20 01:13:38,340 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_3276.pt
[2020-08-20 01:13:50,672 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:13:50,720 INFO] number of examples: 4960
[2020-08-20 01:14:02,609 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_3432.pt
[2020-08-20 01:14:26,814 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_3588.pt
[2020-08-20 01:14:50,917 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_3744.pt
[2020-08-20 01:15:04,893 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:15:04,952 INFO] number of examples: 4960
[2020-08-20 01:15:15,058 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_3900.pt
[2020-08-20 01:15:30,801 INFO] Step 4000/10000; acc:  85.97; ppl:  1.34; xent: 0.30; lr: 0.00198; 2572/2075 tok/s;    625 sec
[2020-08-20 01:15:39,382 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_4056.pt
[2020-08-20 01:16:03,592 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_4212.pt
[2020-08-20 01:16:19,242 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:16:19,290 INFO] number of examples: 4960
[2020-08-20 01:16:27,735 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_4368.pt
[2020-08-20 01:16:52,388 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_4524.pt
[2020-08-20 01:17:16,473 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_4680.pt
[2020-08-20 01:17:33,902 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:17:33,924 INFO] number of examples: 4960
[2020-08-20 01:17:40,629 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_4836.pt
[2020-08-20 01:18:04,647 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_4992.pt
[2020-08-20 01:18:06,129 INFO] Step 5000/10000; acc:  86.55; ppl:  1.32; xent: 0.28; lr: 0.00177; 2567/2072 tok/s;    780 sec
[2020-08-20 01:18:28,640 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_5148.pt
[2020-08-20 01:18:47,673 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:18:48,221 INFO] number of examples: 4960
[2020-08-20 01:18:53,310 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_5304.pt
[2020-08-20 01:19:17,436 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_5460.pt
[2020-08-20 01:19:41,553 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_5616.pt
[2020-08-20 01:20:02,382 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:20:02,403 INFO] number of examples: 4960
[2020-08-20 01:20:05,639 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_5772.pt
[2020-08-20 01:20:29,732 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_5928.pt
[2020-08-20 01:20:41,760 INFO] Step 6000/10000; acc:  86.05; ppl:  1.34; xent: 0.29; lr: 0.00161; 2563/2068 tok/s;    936 sec
[2020-08-20 01:20:54,551 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_6084.pt
[2020-08-20 01:21:17,089 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:21:17,145 INFO] number of examples: 4960
[2020-08-20 01:21:18,747 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_6240.pt
[2020-08-20 01:21:42,881 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_6396.pt
[2020-08-20 01:22:06,836 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_6552.pt
[2020-08-20 01:22:30,752 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_6708.pt
[2020-08-20 01:22:31,157 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:22:31,179 INFO] number of examples: 4960
[2020-08-20 01:22:54,637 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_6864.pt
[2020-08-20 01:23:15,552 INFO] Step 7000/10000; acc:  86.93; ppl:  1.31; xent: 0.27; lr: 0.00149; 2594/2093 tok/s;   1090 sec
[2020-08-20 01:23:18,591 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_7020.pt
[2020-08-20 01:23:43,393 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_7176.pt
[2020-08-20 01:23:46,311 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:23:46,333 INFO] number of examples: 4960
[2020-08-20 01:24:08,128 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_7332.pt
[2020-08-20 01:24:32,045 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_7488.pt
[2020-08-20 01:24:55,943 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_7644.pt
[2020-08-20 01:24:59,830 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:24:59,851 INFO] number of examples: 4960
[2020-08-20 01:25:19,905 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_7800.pt
[2020-08-20 01:25:43,822 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_7956.pt
[2020-08-20 01:25:50,790 INFO] Step 8000/10000; acc:  87.27; ppl:  1.29; xent: 0.26; lr: 0.00140; 2571/2075 tok/s;   1245 sec
[2020-08-20 01:26:07,727 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_8112.pt
[2020-08-20 01:26:13,482 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:26:13,504 INFO] number of examples: 4960
[2020-08-20 01:26:31,858 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_8268.pt
[2020-08-20 01:26:55,737 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_8424.pt
[2020-08-20 01:27:19,689 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_8580.pt
[2020-08-20 01:27:26,922 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:27:26,964 INFO] number of examples: 4960
[2020-08-20 01:27:43,523 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_8736.pt
[2020-08-20 01:28:07,612 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_8892.pt
[2020-08-20 01:28:24,249 INFO] Step 9000/10000; acc:  87.72; ppl:  1.28; xent: 0.25; lr: 0.00132; 2600/2098 tok/s;   1398 sec
[2020-08-20 01:28:31,522 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_9048.pt
[2020-08-20 01:28:40,424 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:28:40,447 INFO] number of examples: 4960
[2020-08-20 01:28:55,409 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_9204.pt
[2020-08-20 01:29:19,360 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_9360.pt
[2020-08-20 01:29:43,466 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_9516.pt
[2020-08-20 01:29:54,289 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:29:54,333 INFO] number of examples: 4960
[2020-08-20 01:30:07,513 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_9672.pt
[2020-08-20 01:30:31,545 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_9828.pt
[2020-08-20 01:30:55,440 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_9984.pt
[2020-08-20 01:30:58,185 INFO] Step 10000/10000; acc:  87.67; ppl:  1.28; xent: 0.25; lr: 0.00125; 2592/2090 tok/s;   1552 sec
[2020-08-20 01:30:58,186 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.valid.0.pt
[2020-08-20 01:30:58,188 INFO] number of examples: 310
[2020-08-20 01:30:58,715 INFO] Validation perplexity: 1.32503
[2020-08-20 01:30:58,715 INFO] Validation accuracy: 88.1869
[2020-08-20 01:30:58,717 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv6/toy_model_step_10000.pt
[2020-08-20 01:31:00,796 INFO]  * src vocab size = 20
[2020-08-20 01:31:00,796 INFO]  * tgt vocab size = 20
[2020-08-20 01:31:00,796 INFO] Building model...
[2020-08-20 01:31:02,904 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=20, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 01:31:02,906 INFO] encoder: 5265920
[2020-08-20 01:31:02,906 INFO] decoder: 6320660
[2020-08-20 01:31:02,906 INFO] * number of parameters: 11586580
[2020-08-20 01:31:02,910 INFO] Starting training on GPU: [0]
[2020-08-20 01:31:02,910 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 01:31:02,910 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:31:02,934 INFO] number of examples: 4960
[2020-08-20 01:31:27,265 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_156.pt
[2020-08-20 01:31:51,598 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_312.pt
[2020-08-20 01:32:15,907 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_468.pt
[2020-08-20 01:32:17,945 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:32:17,992 INFO] number of examples: 4960
[2020-08-20 01:32:40,400 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_624.pt
[2020-08-20 01:33:04,584 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_780.pt
[2020-08-20 01:33:28,876 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_936.pt
[2020-08-20 01:33:32,569 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:33:32,590 INFO] number of examples: 4960
[2020-08-20 01:33:39,103 INFO] Step 1000/10000; acc:  79.07; ppl:  1.62; xent: 0.48; lr: 0.00140; 2555/2062 tok/s;    156 sec
[2020-08-20 01:33:53,315 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_1092.pt
[2020-08-20 01:34:17,632 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_1248.pt
[2020-08-20 01:34:42,044 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_1404.pt
[2020-08-20 01:34:47,392 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:34:47,440 INFO] number of examples: 4960
[2020-08-20 01:35:06,439 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_1560.pt
[2020-08-20 01:35:30,862 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_1716.pt
[2020-08-20 01:35:55,389 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_1872.pt
[2020-08-20 01:36:02,570 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:36:02,592 INFO] number of examples: 4960
[2020-08-20 01:36:15,446 INFO] Step 2000/10000; acc:  85.11; ppl:  1.38; xent: 0.32; lr: 0.00279; 2549/2057 tok/s;    313 sec
[2020-08-20 01:36:19,778 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_2028.pt
[2020-08-20 01:36:44,062 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_2184.pt
[2020-08-20 01:37:08,565 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_2340.pt
[2020-08-20 01:37:18,286 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:37:18,332 INFO] number of examples: 4960
[2020-08-20 01:37:33,827 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_2496.pt
[2020-08-20 01:37:58,169 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_2652.pt
[2020-08-20 01:38:22,540 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_2808.pt
[2020-08-20 01:38:33,147 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:38:33,169 INFO] number of examples: 4960
[2020-08-20 01:38:46,896 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_2964.pt
[2020-08-20 01:38:52,692 INFO] Step 3000/10000; acc:  84.81; ppl:  1.38; xent: 0.32; lr: 0.00228; 2536/2045 tok/s;    470 sec
[2020-08-20 01:39:11,117 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_3120.pt
[2020-08-20 01:39:36,268 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_3276.pt
[2020-08-20 01:39:48,743 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:39:48,793 INFO] number of examples: 4960
[2020-08-20 01:40:00,915 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_3432.pt
[2020-08-20 01:40:25,272 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_3588.pt
[2020-08-20 01:40:49,608 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_3744.pt
[2020-08-20 01:41:03,814 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:41:03,835 INFO] number of examples: 4960
[2020-08-20 01:41:14,077 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_3900.pt
[2020-08-20 01:41:30,690 INFO] Step 4000/10000; acc:  84.81; ppl:  1.38; xent: 0.32; lr: 0.00198; 2524/2036 tok/s;    628 sec
[2020-08-20 01:41:39,306 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_4056.pt
[2020-08-20 01:42:03,647 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_4212.pt
[2020-08-20 01:42:19,630 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:42:19,680 INFO] number of examples: 4960
[2020-08-20 01:42:28,205 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_4368.pt
[2020-08-20 01:42:52,608 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_4524.pt
[2020-08-20 01:43:16,926 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_4680.pt
[2020-08-20 01:43:34,529 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:43:34,551 INFO] number of examples: 4960
[2020-08-20 01:43:41,370 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_4836.pt
[2020-08-20 01:44:05,844 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_4992.pt
[2020-08-20 01:44:07,363 INFO] Step 5000/10000; acc:  86.24; ppl:  1.33; xent: 0.28; lr: 0.00177; 2546/2055 tok/s;    784 sec
[2020-08-20 01:44:30,189 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_5148.pt
[2020-08-20 01:44:49,839 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:44:49,889 INFO] number of examples: 4960
[2020-08-20 01:44:55,021 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_5304.pt
[2020-08-20 01:45:19,490 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_5460.pt
[2020-08-20 01:45:43,869 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_5616.pt
[2020-08-20 01:46:04,932 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:46:04,963 INFO] number of examples: 4960
[2020-08-20 01:46:08,226 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_5772.pt
[2020-08-20 01:46:32,680 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_5928.pt
[2020-08-20 01:46:43,989 INFO] Step 6000/10000; acc:  85.77; ppl:  1.35; xent: 0.30; lr: 0.00161; 2549/2057 tok/s;    941 sec
[2020-08-20 01:46:56,930 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_6084.pt
[2020-08-20 01:47:20,909 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:47:20,931 INFO] number of examples: 4960
[2020-08-20 01:47:22,547 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_6240.pt
[2020-08-20 01:47:46,944 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_6396.pt
[2020-08-20 01:48:11,271 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_6552.pt
[2020-08-20 01:48:35,603 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_6708.pt
[2020-08-20 01:48:36,050 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:48:36,071 INFO] number of examples: 4960
[2020-08-20 01:48:59,736 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_6864.pt
[2020-08-20 01:49:20,869 INFO] Step 7000/10000; acc:  86.73; ppl:  1.31; xent: 0.27; lr: 0.00149; 2543/2051 tok/s;   1098 sec
[2020-08-20 01:49:23,899 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_7020.pt
[2020-08-20 01:49:49,039 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_7176.pt
[2020-08-20 01:49:51,336 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:49:51,358 INFO] number of examples: 4960
[2020-08-20 01:50:13,401 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_7332.pt
[2020-08-20 01:50:37,471 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_7488.pt
[2020-08-20 01:51:01,555 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_7644.pt
[2020-08-20 01:51:05,573 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:51:05,595 INFO] number of examples: 4960
[2020-08-20 01:51:25,741 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_7800.pt
[2020-08-20 01:51:49,936 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_7956.pt
[2020-08-20 01:51:56,960 INFO] Step 8000/10000; acc:  86.54; ppl:  1.31; xent: 0.27; lr: 0.00140; 2556/2063 tok/s;   1254 sec
[2020-08-20 01:52:13,953 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_8112.pt
[2020-08-20 01:52:19,519 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:52:19,541 INFO] number of examples: 4960
[2020-08-20 01:52:37,927 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_8268.pt
[2020-08-20 01:53:01,903 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_8424.pt
[2020-08-20 01:53:25,954 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_8580.pt
[2020-08-20 01:53:33,552 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:53:33,595 INFO] number of examples: 4960
[2020-08-20 01:53:50,372 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_8736.pt
[2020-08-20 01:54:14,371 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_8892.pt
[2020-08-20 01:54:31,084 INFO] Step 9000/10000; acc:  87.15; ppl:  1.30; xent: 0.26; lr: 0.00132; 2588/2089 tok/s;   1408 sec
[2020-08-20 01:54:38,384 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_9048.pt
[2020-08-20 01:54:47,400 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:54:47,422 INFO] number of examples: 4960
[2020-08-20 01:55:02,591 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_9204.pt
[2020-08-20 01:55:26,712 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_9360.pt
[2020-08-20 01:55:50,818 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_9516.pt
[2020-08-20 01:56:01,567 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:56:01,612 INFO] number of examples: 4960
[2020-08-20 01:56:14,844 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_9672.pt
[2020-08-20 01:56:38,749 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_9828.pt
[2020-08-20 01:57:02,775 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_9984.pt
[2020-08-20 01:57:05,615 INFO] Step 10000/10000; acc:  87.21; ppl:  1.30; xent: 0.26; lr: 0.00125; 2583/2085 tok/s;   1563 sec
[2020-08-20 01:57:05,616 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.valid.0.pt
[2020-08-20 01:57:05,634 INFO] number of examples: 310
[2020-08-20 01:57:06,159 INFO] Validation perplexity: 1.30815
[2020-08-20 01:57:06,160 INFO] Validation accuracy: 89.3291
[2020-08-20 01:57:06,161 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv7/toy_model_step_10000.pt
[2020-08-20 01:57:07,646 INFO]  * src vocab size = 20
[2020-08-20 01:57:07,646 INFO]  * tgt vocab size = 20
[2020-08-20 01:57:07,646 INFO] Building model...
[2020-08-20 01:57:09,789 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=20, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 01:57:09,791 INFO] encoder: 5265920
[2020-08-20 01:57:09,791 INFO] decoder: 6320660
[2020-08-20 01:57:09,791 INFO] * number of parameters: 11586580
[2020-08-20 01:57:09,798 INFO] Starting training on GPU: [0]
[2020-08-20 01:57:09,798 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 01:57:09,798 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:57:09,824 INFO] number of examples: 4960
[2020-08-20 01:57:34,154 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_156.pt
[2020-08-20 01:57:58,670 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_312.pt
[2020-08-20 01:58:24,803 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_468.pt
[2020-08-20 01:58:27,833 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:58:27,881 INFO] number of examples: 4960
[2020-08-20 01:58:50,433 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_624.pt
[2020-08-20 01:59:15,307 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_780.pt
[2020-08-20 01:59:39,896 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_936.pt
[2020-08-20 01:59:43,618 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 01:59:43,640 INFO] number of examples: 4960
[2020-08-20 01:59:50,227 INFO] Step 1000/10000; acc:  79.60; ppl:  1.60; xent: 0.47; lr: 0.00140; 2487/2007 tok/s;    160 sec
[2020-08-20 02:00:04,529 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_1092.pt
[2020-08-20 02:00:29,125 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_1248.pt
[2020-08-20 02:00:54,691 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_1404.pt
[2020-08-20 02:01:01,238 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:01:01,283 INFO] number of examples: 4960
[2020-08-20 02:01:20,486 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_1560.pt
[2020-08-20 02:01:45,148 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_1716.pt
[2020-08-20 02:02:09,703 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_1872.pt
[2020-08-20 02:02:17,841 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:02:17,862 INFO] number of examples: 4960
[2020-08-20 02:02:30,723 INFO] Step 2000/10000; acc:  85.17; ppl:  1.37; xent: 0.32; lr: 0.00279; 2487/2006 tok/s;    321 sec
[2020-08-20 02:02:35,084 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_2028.pt
[2020-08-20 02:02:59,585 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_2184.pt
[2020-08-20 02:03:24,040 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_2340.pt
[2020-08-20 02:03:32,937 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:03:32,984 INFO] number of examples: 4960
[2020-08-20 02:03:48,340 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_2496.pt
[2020-08-20 02:04:12,521 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_2652.pt
[2020-08-20 02:04:36,717 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_2808.pt
[2020-08-20 02:04:47,228 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:04:47,249 INFO] number of examples: 4960
[2020-08-20 02:05:00,921 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_2964.pt
[2020-08-20 02:05:07,646 INFO] Step 3000/10000; acc:  85.79; ppl:  1.35; xent: 0.30; lr: 0.00228; 2543/2052 tok/s;    478 sec
[2020-08-20 02:05:26,035 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_3120.pt
[2020-08-20 02:05:50,187 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_3276.pt
[2020-08-20 02:06:02,481 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:06:02,530 INFO] number of examples: 4960
[2020-08-20 02:06:14,472 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_3432.pt
[2020-08-20 02:06:38,615 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_3588.pt
[2020-08-20 02:07:02,802 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_3744.pt
[2020-08-20 02:07:16,947 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:07:16,968 INFO] number of examples: 4960
[2020-08-20 02:07:27,077 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_3900.pt
[2020-08-20 02:07:42,492 INFO] Step 4000/10000; acc:  86.48; ppl:  1.33; xent: 0.28; lr: 0.00198; 2575/2078 tok/s;    633 sec
[2020-08-20 02:07:51,127 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_4056.pt
[2020-08-20 02:08:15,342 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_4212.pt
[2020-08-20 02:08:31,096 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:08:31,144 INFO] number of examples: 4960
[2020-08-20 02:08:39,553 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_4368.pt
[2020-08-20 02:09:03,754 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_4524.pt
[2020-08-20 02:09:27,814 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_4680.pt
[2020-08-20 02:09:45,204 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:09:45,226 INFO] number of examples: 4960
[2020-08-20 02:09:51,968 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_4836.pt
[2020-08-20 02:10:16,175 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_4992.pt
[2020-08-20 02:10:17,802 INFO] Step 5000/10000; acc:  86.39; ppl:  1.32; xent: 0.28; lr: 0.00177; 2569/2073 tok/s;    788 sec
[2020-08-20 02:10:40,432 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_5148.pt
[2020-08-20 02:10:59,636 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:10:59,687 INFO] number of examples: 4960
[2020-08-20 02:11:04,774 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_5304.pt
[2020-08-20 02:11:28,837 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_5460.pt
[2020-08-20 02:11:52,968 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_5616.pt
[2020-08-20 02:12:13,899 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:12:13,920 INFO] number of examples: 4960
[2020-08-20 02:12:17,141 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_5772.pt
[2020-08-20 02:12:41,196 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_5928.pt
[2020-08-20 02:12:52,580 INFO] Step 6000/10000; acc:  87.56; ppl:  1.29; xent: 0.25; lr: 0.00161; 2578/2080 tok/s;    943 sec
[2020-08-20 02:13:05,430 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_6084.pt
[2020-08-20 02:13:29,019 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:13:29,040 INFO] number of examples: 4960
[2020-08-20 02:13:30,628 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_6240.pt
[2020-08-20 02:13:54,804 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_6396.pt
[2020-08-20 02:14:18,862 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_6552.pt
[2020-08-20 02:14:42,706 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_6708.pt
[2020-08-20 02:14:43,256 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:14:43,278 INFO] number of examples: 4960
[2020-08-20 02:15:06,694 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_6864.pt
[2020-08-20 02:15:29,169 INFO] Step 7000/10000; acc:  87.65; ppl:  1.29; xent: 0.25; lr: 0.00149; 2545/2053 tok/s;   1099 sec
[2020-08-20 02:15:32,205 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_7020.pt
[2020-08-20 02:15:56,944 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_7176.pt
[2020-08-20 02:15:59,081 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:15:59,104 INFO] number of examples: 4960
[2020-08-20 02:16:20,885 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_7332.pt
[2020-08-20 02:16:44,369 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_7488.pt
[2020-08-20 02:17:08,196 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_7644.pt
[2020-08-20 02:17:12,124 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:17:12,146 INFO] number of examples: 4960
[2020-08-20 02:17:32,045 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_7800.pt
[2020-08-20 02:17:55,991 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_7956.pt
[2020-08-20 02:18:02,892 INFO] Step 8000/10000; acc:  87.63; ppl:  1.29; xent: 0.25; lr: 0.00140; 2596/2094 tok/s;   1253 sec
[2020-08-20 02:18:19,749 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_8112.pt
[2020-08-20 02:18:25,279 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:18:25,301 INFO] number of examples: 4960
[2020-08-20 02:18:43,592 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_8268.pt
[2020-08-20 02:19:07,410 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_8424.pt
[2020-08-20 02:19:32,295 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_8580.pt
[2020-08-20 02:19:39,589 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:19:39,631 INFO] number of examples: 4960
[2020-08-20 02:19:56,275 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_8736.pt
[2020-08-20 02:20:20,113 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_8892.pt
[2020-08-20 02:20:36,907 INFO] Step 9000/10000; acc:  87.75; ppl:  1.28; xent: 0.24; lr: 0.00132; 2590/2090 tok/s;   1407 sec
[2020-08-20 02:20:44,138 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_9048.pt
[2020-08-20 02:20:53,097 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:20:53,120 INFO] number of examples: 4960
[2020-08-20 02:21:08,148 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_9204.pt
[2020-08-20 02:21:32,047 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_9360.pt
[2020-08-20 02:21:55,951 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_9516.pt
[2020-08-20 02:22:06,710 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:22:06,759 INFO] number of examples: 4960
[2020-08-20 02:22:19,894 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_9672.pt
[2020-08-20 02:22:43,732 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_9828.pt
[2020-08-20 02:23:07,632 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_9984.pt
[2020-08-20 02:23:10,302 INFO] Step 10000/10000; acc:  87.90; ppl:  1.27; xent: 0.24; lr: 0.00125; 2599/2097 tok/s;   1561 sec
[2020-08-20 02:23:10,303 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.valid.0.pt
[2020-08-20 02:23:10,336 INFO] number of examples: 310
[2020-08-20 02:23:10,870 INFO] Validation perplexity: 1.29189
[2020-08-20 02:23:10,871 INFO] Validation accuracy: 89.5966
[2020-08-20 02:23:10,872 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv8/toy_model_step_10000.pt
[2020-08-20 02:23:12,339 INFO]  * src vocab size = 20
[2020-08-20 02:23:12,339 INFO]  * tgt vocab size = 20
[2020-08-20 02:23:12,339 INFO] Building model...
[2020-08-20 02:23:14,476 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=20, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 02:23:14,478 INFO] encoder: 5265920
[2020-08-20 02:23:14,478 INFO] decoder: 6320660
[2020-08-20 02:23:14,478 INFO] * number of parameters: 11586580
[2020-08-20 02:23:14,485 INFO] Starting training on GPU: [0]
[2020-08-20 02:23:14,485 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 02:23:14,485 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:23:14,510 INFO] number of examples: 4960
[2020-08-20 02:23:38,624 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_156.pt
[2020-08-20 02:24:02,864 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_312.pt
[2020-08-20 02:24:27,011 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_468.pt
[2020-08-20 02:24:29,009 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:24:29,057 INFO] number of examples: 4960
[2020-08-20 02:24:51,224 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_624.pt
[2020-08-20 02:25:15,467 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_780.pt
[2020-08-20 02:25:39,563 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_936.pt
[2020-08-20 02:25:43,317 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:25:43,338 INFO] number of examples: 4960
[2020-08-20 02:25:49,804 INFO] Step 1000/10000; acc:  79.45; ppl:  1.60; xent: 0.47; lr: 0.00140; 2569/2073 tok/s;    155 sec
[2020-08-20 02:26:03,955 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_1092.pt
[2020-08-20 02:26:28,237 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_1248.pt
[2020-08-20 02:26:52,527 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_1404.pt
[2020-08-20 02:26:57,890 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:26:57,936 INFO] number of examples: 4960
[2020-08-20 02:27:16,766 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_1560.pt
[2020-08-20 02:27:41,046 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_1716.pt
[2020-08-20 02:28:05,331 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_1872.pt
[2020-08-20 02:28:12,783 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:28:12,805 INFO] number of examples: 4960
[2020-08-20 02:28:25,586 INFO] Step 2000/10000; acc:  85.54; ppl:  1.37; xent: 0.31; lr: 0.00279; 2560/2066 tok/s;    311 sec
[2020-08-20 02:28:29,882 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_2028.pt
[2020-08-20 02:28:55,180 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_2184.pt
[2020-08-20 02:29:19,489 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_2340.pt
[2020-08-20 02:29:28,377 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:29:28,424 INFO] number of examples: 4960
[2020-08-20 02:29:43,726 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_2496.pt
[2020-08-20 02:30:07,920 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_2652.pt
[2020-08-20 02:30:32,263 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_2808.pt
[2020-08-20 02:30:42,930 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:30:42,953 INFO] number of examples: 4960
[2020-08-20 02:30:56,580 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_2964.pt
[2020-08-20 02:31:02,422 INFO] Step 3000/10000; acc:  85.85; ppl:  1.35; xent: 0.30; lr: 0.00228; 2545/2053 tok/s;    468 sec
[2020-08-20 02:31:20,812 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_3120.pt
[2020-08-20 02:31:45,059 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_3276.pt
[2020-08-20 02:31:57,334 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:31:57,383 INFO] number of examples: 4960
[2020-08-20 02:32:09,324 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_3432.pt
[2020-08-20 02:32:33,440 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_3588.pt
[2020-08-20 02:32:57,653 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_3744.pt
[2020-08-20 02:33:11,799 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:33:11,821 INFO] number of examples: 4960
[2020-08-20 02:33:21,918 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_3900.pt
[2020-08-20 02:33:38,234 INFO] Step 4000/10000; acc:  86.71; ppl:  1.32; xent: 0.28; lr: 0.00198; 2560/2066 tok/s;    624 sec
[2020-08-20 02:33:46,825 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_4056.pt
[2020-08-20 02:34:11,012 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_4212.pt
[2020-08-20 02:34:26,773 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:34:26,824 INFO] number of examples: 4960
[2020-08-20 02:34:35,231 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_4368.pt
[2020-08-20 02:34:59,587 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_4524.pt
[2020-08-20 02:35:23,757 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_4680.pt
[2020-08-20 02:35:41,198 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:35:41,220 INFO] number of examples: 4960
[2020-08-20 02:35:47,947 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_4836.pt
[2020-08-20 02:36:12,097 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_4992.pt
[2020-08-20 02:36:13,826 INFO] Step 5000/10000; acc:  87.24; ppl:  1.30; xent: 0.26; lr: 0.00177; 2563/2068 tok/s;    779 sec
[2020-08-20 02:36:36,526 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_5148.pt
[2020-08-20 02:36:55,649 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:36:55,700 INFO] number of examples: 4960
[2020-08-20 02:37:00,763 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_5304.pt
[2020-08-20 02:37:25,811 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_5460.pt
[2020-08-20 02:37:49,961 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_5616.pt
[2020-08-20 02:38:10,956 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:38:10,978 INFO] number of examples: 4960
[2020-08-20 02:38:14,214 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_5772.pt
[2020-08-20 02:38:39,150 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_5928.pt
[2020-08-20 02:38:50,491 INFO] Step 6000/10000; acc:  85.59; ppl:  1.36; xent: 0.31; lr: 0.00161; 2545/2054 tok/s;    936 sec
[2020-08-20 02:39:03,338 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_6084.pt
[2020-08-20 02:39:29,492 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:39:29,514 INFO] number of examples: 4960
[2020-08-20 02:39:31,113 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_6240.pt
[2020-08-20 02:39:55,264 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_6396.pt
[2020-08-20 02:40:19,919 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_6552.pt
[2020-08-20 02:40:43,608 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_6708.pt
[2020-08-20 02:40:44,084 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:40:44,106 INFO] number of examples: 4960
[2020-08-20 02:41:07,775 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_6864.pt
[2020-08-20 02:41:28,752 INFO] Step 7000/10000; acc:  87.48; ppl:  1.29; xent: 0.25; lr: 0.00149; 2521/2034 tok/s;   1094 sec
[2020-08-20 02:41:31,793 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_7020.pt
[2020-08-20 02:41:55,808 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_7176.pt
[2020-08-20 02:41:57,957 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:41:57,979 INFO] number of examples: 4960
[2020-08-20 02:42:19,710 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_7332.pt
[2020-08-20 02:42:43,606 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_7488.pt
[2020-08-20 02:43:07,819 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_7644.pt
[2020-08-20 02:43:11,780 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:43:11,803 INFO] number of examples: 4960
[2020-08-20 02:43:31,716 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_7800.pt
[2020-08-20 02:43:57,356 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_7956.pt
[2020-08-20 02:44:04,357 INFO] Step 8000/10000; acc:  87.60; ppl:  1.29; xent: 0.25; lr: 0.00140; 2564/2069 tok/s;   1250 sec
[2020-08-20 02:44:21,297 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_8112.pt
[2020-08-20 02:44:26,815 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:44:26,838 INFO] number of examples: 4960
[2020-08-20 02:44:45,100 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_8268.pt
[2020-08-20 02:45:09,007 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_8424.pt
[2020-08-20 02:45:32,983 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_8580.pt
[2020-08-20 02:45:40,410 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:45:40,453 INFO] number of examples: 4960
[2020-08-20 02:45:57,073 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_8736.pt
[2020-08-20 02:46:20,919 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_8892.pt
[2020-08-20 02:46:37,536 INFO] Step 9000/10000; acc:  88.22; ppl:  1.26; xent: 0.23; lr: 0.00132; 2603/2101 tok/s;   1403 sec
[2020-08-20 02:46:44,763 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_9048.pt
[2020-08-20 02:46:53,650 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:46:53,672 INFO] number of examples: 4960
[2020-08-20 02:47:08,614 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_9204.pt
[2020-08-20 02:47:32,555 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_9360.pt
[2020-08-20 02:47:56,352 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_9516.pt
[2020-08-20 02:48:06,975 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:48:07,019 INFO] number of examples: 4960
[2020-08-20 02:48:20,168 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_9672.pt
[2020-08-20 02:48:45,439 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_9828.pt
[2020-08-20 02:49:09,318 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_9984.pt
[2020-08-20 02:49:13,401 INFO] Step 10000/10000; acc:  86.95; ppl:  1.30; xent: 0.26; lr: 0.00125; 2562/2067 tok/s;   1559 sec
[2020-08-20 02:49:13,402 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.valid.0.pt
[2020-08-20 02:49:13,405 INFO] number of examples: 310
[2020-08-20 02:49:13,943 INFO] Validation perplexity: 1.35824
[2020-08-20 02:49:13,943 INFO] Validation accuracy: 86.9212
[2020-08-20 02:49:13,944 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv9/toy_model_step_10000.pt
[2020-08-20 02:49:15,411 INFO]  * src vocab size = 20
[2020-08-20 02:49:15,411 INFO]  * tgt vocab size = 20
[2020-08-20 02:49:15,411 INFO] Building model...
[2020-08-20 02:49:17,539 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(20, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=20, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-08-20 02:49:17,541 INFO] encoder: 5265920
[2020-08-20 02:49:17,541 INFO] decoder: 6320660
[2020-08-20 02:49:17,541 INFO] * number of parameters: 11586580
[2020-08-20 02:49:17,558 INFO] Starting training on GPU: [0]
[2020-08-20 02:49:17,558 INFO] Start training loop and validate every 10000 steps...
[2020-08-20 02:49:17,558 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:49:17,584 INFO] number of examples: 4960
[2020-08-20 02:49:41,404 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_156.pt
[2020-08-20 02:50:05,305 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_312.pt
[2020-08-20 02:50:30,337 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_468.pt
[2020-08-20 02:50:35,311 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:50:35,358 INFO] number of examples: 4960
[2020-08-20 02:50:57,335 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_624.pt
[2020-08-20 02:51:21,229 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_780.pt
[2020-08-20 02:51:45,267 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_936.pt
[2020-08-20 02:51:48,957 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:51:48,978 INFO] number of examples: 4960
[2020-08-20 02:51:55,358 INFO] Step 1000/10000; acc:  79.03; ppl:  1.62; xent: 0.48; lr: 0.00140; 2530/2042 tok/s;    158 sec
[2020-08-20 02:52:09,280 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_1092.pt
[2020-08-20 02:52:33,211 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_1248.pt
[2020-08-20 02:52:57,130 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_1404.pt
[2020-08-20 02:53:02,606 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:53:02,656 INFO] number of examples: 4960
[2020-08-20 02:53:21,271 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_1560.pt
[2020-08-20 02:53:45,176 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_1716.pt
[2020-08-20 02:54:09,208 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_1872.pt
[2020-08-20 02:54:16,360 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:54:16,381 INFO] number of examples: 4960
[2020-08-20 02:54:28,945 INFO] Step 2000/10000; acc:  84.96; ppl:  1.38; xent: 0.32; lr: 0.00279; 2598/2096 tok/s;    311 sec
[2020-08-20 02:54:33,183 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_2028.pt
[2020-08-20 02:54:57,102 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_2184.pt
[2020-08-20 02:55:21,099 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_2340.pt
[2020-08-20 02:55:30,007 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:55:30,054 INFO] number of examples: 4960
[2020-08-20 02:55:45,285 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_2496.pt
[2020-08-20 02:56:09,280 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_2652.pt
[2020-08-20 02:56:33,290 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_2808.pt
[2020-08-20 02:56:43,808 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:56:43,830 INFO] number of examples: 4960
[2020-08-20 02:56:57,286 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_2964.pt
[2020-08-20 02:57:03,006 INFO] Step 3000/10000; acc:  85.36; ppl:  1.36; xent: 0.31; lr: 0.00228; 2590/2089 tok/s;    465 sec
[2020-08-20 02:57:21,161 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_3120.pt
[2020-08-20 02:57:44,846 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_3276.pt
[2020-08-20 02:57:56,812 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:57:56,860 INFO] number of examples: 4960
[2020-08-20 02:58:08,532 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_3432.pt
[2020-08-20 02:58:32,046 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_3588.pt
[2020-08-20 02:58:55,694 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_3744.pt
[2020-08-20 02:59:09,410 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 02:59:09,439 INFO] number of examples: 4960
[2020-08-20 02:59:19,331 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_3900.pt
[2020-08-20 02:59:36,336 INFO] Step 4000/10000; acc:  85.88; ppl:  1.35; xent: 0.30; lr: 0.00198; 2602/2100 tok/s;    619 sec
[2020-08-20 02:59:44,615 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_4056.pt
[2020-08-20 03:00:08,185 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_4212.pt
[2020-08-20 03:00:23,626 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 03:00:23,676 INFO] number of examples: 4960
[2020-08-20 03:00:31,912 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_4368.pt
[2020-08-20 03:00:55,496 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_4524.pt
[2020-08-20 03:01:19,066 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_4680.pt
[2020-08-20 03:01:36,147 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 03:01:36,169 INFO] number of examples: 4960
[2020-08-20 03:01:42,755 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_4836.pt
[2020-08-20 03:02:06,264 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_4992.pt
[2020-08-20 03:02:07,757 INFO] Step 5000/10000; acc:  86.17; ppl:  1.34; xent: 0.29; lr: 0.00177; 2634/2126 tok/s;    770 sec
[2020-08-20 03:02:29,865 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_5148.pt
[2020-08-20 03:02:48,616 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 03:02:48,665 INFO] number of examples: 4960
[2020-08-20 03:02:53,622 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_5304.pt
[2020-08-20 03:03:18,098 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_5460.pt
[2020-08-20 03:03:42,825 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_5616.pt
[2020-08-20 03:04:03,260 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 03:04:03,282 INFO] number of examples: 4960
[2020-08-20 03:04:06,463 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_5772.pt
[2020-08-20 03:04:31,088 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_5928.pt
[2020-08-20 03:04:42,106 INFO] Step 6000/10000; acc:  86.58; ppl:  1.32; xent: 0.28; lr: 0.00161; 2584/2085 tok/s;    925 sec
[2020-08-20 03:04:54,670 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_6084.pt
[2020-08-20 03:05:16,750 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 03:05:16,772 INFO] number of examples: 4960
[2020-08-20 03:05:18,331 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_6240.pt
[2020-08-20 03:05:41,855 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_6396.pt
[2020-08-20 03:06:08,134 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_6552.pt
[2020-08-20 03:06:31,753 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_6708.pt
[2020-08-20 03:06:32,199 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 03:06:32,221 INFO] number of examples: 4960
[2020-08-20 03:06:55,314 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_6864.pt
[2020-08-20 03:07:15,805 INFO] Step 7000/10000; acc:  87.23; ppl:  1.30; xent: 0.26; lr: 0.00149; 2596/2095 tok/s;   1078 sec
[2020-08-20 03:07:18,800 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_7020.pt
[2020-08-20 03:07:42,545 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_7176.pt
[2020-08-20 03:07:44,582 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 03:07:44,605 INFO] number of examples: 4960
[2020-08-20 03:08:06,033 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_7332.pt
[2020-08-20 03:08:29,506 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_7488.pt
[2020-08-20 03:08:53,108 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_7644.pt
[2020-08-20 03:08:56,981 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 03:08:57,002 INFO] number of examples: 4960
[2020-08-20 03:09:16,583 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_7800.pt
[2020-08-20 03:09:39,839 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_7956.pt
[2020-08-20 03:09:46,660 INFO] Step 8000/10000; acc:  87.00; ppl:  1.30; xent: 0.26; lr: 0.00140; 2645/2134 tok/s;   1229 sec
[2020-08-20 03:10:03,203 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_8112.pt
[2020-08-20 03:10:08,720 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 03:10:08,742 INFO] number of examples: 4960
[2020-08-20 03:10:26,590 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_8268.pt
[2020-08-20 03:10:51,286 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_8424.pt
[2020-08-20 03:11:14,666 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_8580.pt
[2020-08-20 03:11:21,801 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 03:11:21,846 INFO] number of examples: 4960
[2020-08-20 03:11:38,119 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_8736.pt
[2020-08-20 03:12:01,407 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_8892.pt
[2020-08-20 03:12:17,963 INFO] Step 9000/10000; acc:  85.05; ppl:  1.36; xent: 0.31; lr: 0.00132; 2636/2127 tok/s;   1380 sec
[2020-08-20 03:12:25,050 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_9048.pt
[2020-08-20 03:12:33,806 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 03:12:33,827 INFO] number of examples: 4960
[2020-08-20 03:12:48,452 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_9204.pt
[2020-08-20 03:13:11,775 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_9360.pt
[2020-08-20 03:13:35,240 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_9516.pt
[2020-08-20 03:13:46,763 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.train.0.pt
[2020-08-20 03:13:46,806 INFO] number of examples: 4960
[2020-08-20 03:13:59,661 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_9672.pt
[2020-08-20 03:14:23,070 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_9828.pt
[2020-08-20 03:14:46,429 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_9984.pt
[2020-08-20 03:14:49,182 INFO] Step 10000/10000; acc:  86.81; ppl:  1.31; xent: 0.27; lr: 0.00125; 2636/2127 tok/s;   1532 sec
[2020-08-20 03:14:49,183 INFO] Loading dataset from /home/dpk25/rds/hpc-work/toy_model/data_sear_biased/.valid.0.pt
[2020-08-20 03:14:49,197 INFO] number of examples: 310
[2020-08-20 03:14:49,722 INFO] Validation perplexity: 1.32377
[2020-08-20 03:14:49,722 INFO] Validation accuracy: 88.8866
[2020-08-20 03:14:49,724 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/toy_model/sear_models_biased_conv10/toy_model_step_10000.pt
