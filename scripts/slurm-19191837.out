Changed directory to /home/dpk25/MolecularTransformer2/scripts.

JobID: 19191837
======
Time: Sun  2 Feb 21:42:09 GMT 2020
Running on master node: gpu-e-68
Current directory: /home/dpk25/MolecularTransformer2/scripts

Nodes allocated:
================
gpu-e-68

numtasks=1, numnodes=1, mpi_tasks_per_node=1 (OMP_NUM_THREADS=1)

Executing command:
==================
./train.sh 

[2020-02-02 21:42:10,264 INFO] Loading checkpoint from /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_390000.pt
[2020-02-02 21:42:10,355 INFO] Loading vocab from checkpoint at /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_390000.pt.
[2020-02-02 21:42:10,355 INFO]  * src vocab size = 297
[2020-02-02 21:42:10,355 INFO]  * tgt vocab size = 297
[2020-02-02 21:42:10,355 INFO] Building model...
[2020-02-02 21:42:18,324 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(297, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(297, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=256, out_features=297, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-02-02 21:42:18,326 INFO] encoder: 5336832
[2020-02-02 21:42:18,326 INFO] decoder: 6391849
[2020-02-02 21:42:18,326 INFO] * number of parameters: 11728681
[2020-02-02 21:42:18,420 INFO] Starting training on GPU: [0]
[2020-02-02 21:42:18,420 INFO] Start training loop and validate every 10000 steps...
[2020-02-02 21:42:18,420 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-02 21:42:28,357 INFO] number of examples: 818070
[2020-02-02 21:47:49,541 INFO] Step 391000/500000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00020; 47582/28979 tok/s;    331 sec
[2020-02-02 21:53:07,413 INFO] Step 392000/500000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00020; 49567/30231 tok/s;    649 sec
[2020-02-02 21:58:24,454 INFO] Step 393000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49685/30329 tok/s;    966 sec
[2020-02-02 22:01:19,014 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-02 22:01:34,863 INFO] number of examples: 818070
[2020-02-02 22:04:01,507 INFO] Step 394000/500000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00020; 46729/28531 tok/s;   1303 sec
[2020-02-02 22:09:20,231 INFO] Step 395000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49428/30094 tok/s;   1622 sec
[2020-02-02 22:14:39,674 INFO] Step 396000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49334/30100 tok/s;   1941 sec
[2020-02-02 22:19:58,641 INFO] Step 397000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49377/30132 tok/s;   2260 sec
[2020-02-02 22:20:30,286 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-02 22:20:40,020 INFO] number of examples: 818070
[2020-02-02 22:25:29,389 INFO] Step 398000/500000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00020; 47625/29074 tok/s;   2591 sec
[2020-02-02 22:30:47,499 INFO] Step 399000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49531/30137 tok/s;   2909 sec
[2020-02-02 22:36:05,791 INFO] Step 400000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49488/30216 tok/s;   3227 sec
[2020-02-02 22:36:05,792 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.valid.0.pt
[2020-02-02 22:36:08,527 INFO] number of examples: 30000
[2020-02-02 22:36:38,627 INFO] Validation perplexity: 1.02953
[2020-02-02 22:36:38,628 INFO] Validation accuracy: 99.5293
[2020-02-02 22:36:38,631 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_400000.pt
[2020-02-02 22:40:05,864 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-02 22:40:21,085 INFO] number of examples: 818070
[2020-02-02 22:42:16,290 INFO] Step 401000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 42514/25978 tok/s;   3598 sec
[2020-02-02 22:47:35,340 INFO] Step 402000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49376/30044 tok/s;   3917 sec
[2020-02-02 22:52:54,770 INFO] Step 403000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49335/30143 tok/s;   4236 sec
[2020-02-02 22:58:13,783 INFO] Step 404000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49377/30101 tok/s;   4555 sec
[2020-02-02 22:59:17,454 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-02 22:59:32,161 INFO] number of examples: 818070
[2020-02-02 23:03:50,207 INFO] Step 405000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 46816/28599 tok/s;   4892 sec
[2020-02-02 23:09:08,563 INFO] Step 406000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49496/30098 tok/s;   5210 sec
[2020-02-02 23:14:27,315 INFO] Step 407000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49412/30163 tok/s;   5529 sec
[2020-02-02 23:18:25,424 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-02 23:18:37,361 INFO] number of examples: 818070
[2020-02-02 23:20:00,622 INFO] Step 408000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 47260/28846 tok/s;   5862 sec
[2020-02-02 23:25:19,831 INFO] Step 409000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49353/30113 tok/s;   6181 sec
[2020-02-02 23:30:39,367 INFO] Step 410000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00020; 49312/30070 tok/s;   6501 sec
[2020-02-02 23:30:39,369 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.valid.0.pt
[2020-02-02 23:30:39,542 INFO] number of examples: 30000
[2020-02-02 23:31:09,748 INFO] Validation perplexity: 1.03004
[2020-02-02 23:31:09,749 INFO] Validation accuracy: 99.5254
[2020-02-02 23:31:09,751 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_410000.pt
[2020-02-02 23:36:28,658 INFO] Step 411000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00019; 45096/27500 tok/s;   6850 sec
[2020-02-02 23:38:03,942 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-02 23:38:18,727 INFO] number of examples: 818070
[2020-02-02 23:42:05,318 INFO] Step 412000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00019; 46786/28569 tok/s;   7187 sec
[2020-02-02 23:47:23,680 INFO] Step 413000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00019; 49493/30078 tok/s;   7505 sec
[2020-02-02 23:52:42,381 INFO] Step 414000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49421/30274 tok/s;   7824 sec
[2020-02-02 23:57:12,019 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-02 23:57:27,540 INFO] number of examples: 818070
[2020-02-02 23:58:18,819 INFO] Step 415000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 46824/28481 tok/s;   8160 sec
[2020-02-03 00:03:38,431 INFO] Step 416000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00019; 49298/30132 tok/s;   8480 sec
[2020-02-03 00:08:57,395 INFO] Step 417000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00019; 49393/30094 tok/s;   8799 sec
[2020-02-03 00:14:16,166 INFO] Step 418000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49412/30147 tok/s;   9118 sec
[2020-02-03 00:16:23,089 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 00:16:38,534 INFO] number of examples: 818070
[2020-02-03 00:19:53,345 INFO] Step 419000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00019; 46715/28434 tok/s;   9455 sec
[2020-02-03 00:25:11,819 INFO] Step 420000/500000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00019; 49476/30146 tok/s;   9773 sec
[2020-02-03 00:25:11,821 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.valid.0.pt
[2020-02-03 00:25:11,989 INFO] number of examples: 30000
[2020-02-03 00:25:42,167 INFO] Validation perplexity: 1.03038
[2020-02-03 00:25:42,167 INFO] Validation accuracy: 99.5183
[2020-02-03 00:25:42,169 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_420000.pt
[2020-02-03 00:31:01,562 INFO] Step 421000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 45042/27534 tok/s;  10123 sec
[2020-02-03 00:36:03,971 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 00:36:20,158 INFO] number of examples: 818070
[2020-02-03 00:36:40,207 INFO] Step 422000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 46511/28339 tok/s;  10462 sec
[2020-02-03 00:41:59,413 INFO] Step 423000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49356/30096 tok/s;  10781 sec
[2020-02-03 00:47:17,662 INFO] Step 424000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49512/30239 tok/s;  11099 sec
[2020-02-03 00:52:36,515 INFO] Step 425000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49404/30137 tok/s;  11418 sec
[2020-02-03 00:55:14,968 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 00:55:26,275 INFO] number of examples: 818070
[2020-02-03 00:58:09,448 INFO] Step 426000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 47305/28836 tok/s;  11751 sec
[2020-02-03 01:03:28,295 INFO] Step 427000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49412/30117 tok/s;  12070 sec
[2020-02-03 01:08:47,518 INFO] Step 428000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49353/30122 tok/s;  12389 sec
[2020-02-03 01:14:06,278 INFO] Step 429000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49414/30151 tok/s;  12708 sec
[2020-02-03 01:14:21,345 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 01:14:35,846 INFO] number of examples: 818070
[2020-02-03 01:19:42,394 INFO] Step 430000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 46874/28565 tok/s;  13044 sec
[2020-02-03 01:19:42,395 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.valid.0.pt
[2020-02-03 01:19:47,234 INFO] number of examples: 30000
[2020-02-03 01:20:17,430 INFO] Validation perplexity: 1.03028
[2020-02-03 01:20:17,430 INFO] Validation accuracy: 99.5224
[2020-02-03 01:20:17,433 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_430000.pt
[2020-02-03 01:25:36,601 INFO] Step 431000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 44480/27047 tok/s;  13398 sec
[2020-02-03 01:30:55,638 INFO] Step 432000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49378/30212 tok/s;  13717 sec
[2020-02-03 01:34:06,410 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 01:34:30,931 INFO] number of examples: 818070
[2020-02-03 01:36:42,899 INFO] Step 433000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 45356/27687 tok/s;  14064 sec
[2020-02-03 01:42:01,606 INFO] Step 434000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49431/30099 tok/s;  14383 sec
[2020-02-03 01:47:21,094 INFO] Step 435000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49322/30125 tok/s;  14703 sec
[2020-02-03 01:52:39,983 INFO] Step 436000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49396/30097 tok/s;  15022 sec
[2020-02-03 01:53:26,538 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 01:53:42,672 INFO] number of examples: 818070
[2020-02-03 01:58:17,851 INFO] Step 437000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 46618/28481 tok/s;  15359 sec
[2020-02-03 02:03:36,785 INFO] Step 438000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49407/30069 tok/s;  15678 sec
[2020-02-03 02:08:55,693 INFO] Step 439000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49387/30095 tok/s;  15997 sec
[2020-02-03 02:12:37,912 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 02:12:49,589 INFO] number of examples: 818070
[2020-02-03 02:14:29,359 INFO] Step 440000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 47210/28828 tok/s;  16331 sec
[2020-02-03 02:14:29,360 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.valid.0.pt
[2020-02-03 02:14:29,532 INFO] number of examples: 30000
[2020-02-03 02:14:59,706 INFO] Validation perplexity: 1.03069
[2020-02-03 02:14:59,707 INFO] Validation accuracy: 99.5244
[2020-02-03 02:14:59,709 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_440000.pt
[2020-02-03 02:20:18,634 INFO] Step 441000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 45103/27557 tok/s;  16680 sec
[2020-02-03 02:25:37,427 INFO] Step 442000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49431/30124 tok/s;  16999 sec
[2020-02-03 02:30:55,670 INFO] Step 443000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49497/30231 tok/s;  17317 sec
[2020-02-03 02:32:13,938 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 02:32:32,480 INFO] number of examples: 818070
[2020-02-03 02:36:36,049 INFO] Step 444000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 46270/28219 tok/s;  17658 sec
[2020-02-03 02:41:54,795 INFO] Step 445000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00019; 49437/30057 tok/s;  17976 sec
[2020-02-03 02:47:14,074 INFO] Step 446000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49331/30184 tok/s;  18296 sec
[2020-02-03 02:51:27,805 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 02:51:39,664 INFO] number of examples: 818070
[2020-02-03 02:52:47,352 INFO] Step 447000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 47265/28793 tok/s;  18629 sec
[2020-02-03 02:58:06,063 INFO] Step 448000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49437/30198 tok/s;  18948 sec
[2020-02-03 03:03:24,905 INFO] Step 449000/500000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00019; 49414/30115 tok/s;  19266 sec
[2020-02-03 03:08:43,119 INFO] Step 450000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00019; 49498/30177 tok/s;  19585 sec
[2020-02-03 03:08:43,121 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.valid.0.pt
[2020-02-03 03:08:48,087 INFO] number of examples: 30000
[2020-02-03 03:09:18,284 INFO] Validation perplexity: 1.03087
[2020-02-03 03:09:18,286 INFO] Validation accuracy: 99.5309
[2020-02-03 03:09:18,289 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_450000.pt
[2020-02-03 03:11:08,913 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 03:11:33,337 INFO] number of examples: 818070
[2020-02-03 03:15:05,618 INFO] Step 451000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00019; 41182/25097 tok/s;  19967 sec
[2020-02-03 03:20:24,680 INFO] Step 452000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00019; 49385/30084 tok/s;  20286 sec
[2020-02-03 03:25:43,897 INFO] Step 453000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00019; 49345/30208 tok/s;  20605 sec
[2020-02-03 03:30:28,853 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 03:30:44,890 INFO] number of examples: 818070
[2020-02-03 03:31:21,347 INFO] Step 454000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00019; 46675/28407 tok/s;  20943 sec
[2020-02-03 03:36:40,645 INFO] Step 455000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00019; 49346/30096 tok/s;  21262 sec
[2020-02-03 03:41:58,855 INFO] Step 456000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00019; 49512/30187 tok/s;  21580 sec
[2020-02-03 03:47:17,931 INFO] Step 457000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49368/30164 tok/s;  21900 sec
[2020-02-03 03:49:40,497 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 03:49:52,635 INFO] number of examples: 818070
[2020-02-03 03:52:53,207 INFO] Step 458000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 46978/28599 tok/s;  22235 sec
[2020-02-03 03:58:11,334 INFO] Step 459000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49526/30200 tok/s;  22553 sec
[2020-02-03 04:03:30,664 INFO] Step 460000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49332/30120 tok/s;  22872 sec
[2020-02-03 04:03:30,665 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.valid.0.pt
[2020-02-03 04:03:30,832 INFO] number of examples: 30000
[2020-02-03 04:04:01,077 INFO] Validation perplexity: 1.03112
[2020-02-03 04:04:01,078 INFO] Validation accuracy: 99.5245
[2020-02-03 04:04:01,080 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_460000.pt
[2020-02-03 04:09:18,693 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 04:09:33,079 INFO] number of examples: 818070
[2020-02-03 04:09:37,899 INFO] Step 461000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 42892/26138 tok/s;  23239 sec
[2020-02-03 04:14:55,816 INFO] Step 462000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49557/30209 tok/s;  23557 sec
[2020-02-03 04:20:14,297 INFO] Step 463000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49474/30165 tok/s;  23876 sec
[2020-02-03 04:25:32,095 INFO] Step 464000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49567/30260 tok/s;  24194 sec
[2020-02-03 04:28:25,617 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 04:28:39,423 INFO] number of examples: 818070
[2020-02-03 04:31:07,271 INFO] Step 465000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 46991/28689 tok/s;  24529 sec
[2020-02-03 04:36:24,926 INFO] Step 466000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49594/30183 tok/s;  24847 sec
[2020-02-03 04:41:43,328 INFO] Step 467000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49495/30212 tok/s;  25165 sec
[2020-02-03 04:47:00,611 INFO] Step 468000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49638/30295 tok/s;  25482 sec
[2020-02-03 04:47:30,433 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 04:47:44,017 INFO] number of examples: 818070
[2020-02-03 04:52:32,410 INFO] Step 469000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 47474/28978 tok/s;  25814 sec
[2020-02-03 04:57:47,662 INFO] Step 470000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49981/30395 tok/s;  26129 sec
[2020-02-03 04:57:47,664 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.valid.0.pt
[2020-02-03 04:57:47,827 INFO] number of examples: 30000
[2020-02-03 04:58:17,852 INFO] Validation perplexity: 1.03083
[2020-02-03 04:58:17,852 INFO] Validation accuracy: 99.5304
[2020-02-03 04:58:17,854 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_470000.pt
[2020-02-03 05:03:33,870 INFO] Step 471000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 45499/27803 tok/s;  26475 sec
[2020-02-03 05:06:57,516 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 05:07:14,411 INFO] number of examples: 818070
[2020-02-03 05:09:09,442 INFO] Step 472000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 46939/28669 tok/s;  26811 sec
[2020-02-03 05:14:24,610 INFO] Step 473000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49983/30416 tok/s;  27126 sec
[2020-02-03 05:19:40,309 INFO] Step 474000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49919/30493 tok/s;  27442 sec
[2020-02-03 05:24:55,145 INFO] Step 475000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 50033/30501 tok/s;  27757 sec
[2020-02-03 05:25:56,432 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 05:26:07,401 INFO] number of examples: 818070
[2020-02-03 05:30:24,542 INFO] Step 476000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 47814/29216 tok/s;  28086 sec
[2020-02-03 05:35:39,789 INFO] Step 477000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49984/30395 tok/s;  28401 sec
[2020-02-03 05:40:55,467 INFO] Step 478000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49893/30440 tok/s;  28717 sec
[2020-02-03 05:44:49,996 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 05:45:06,921 INFO] number of examples: 818070
[2020-02-03 05:46:30,510 INFO] Step 479000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 47016/28715 tok/s;  29052 sec
[2020-02-03 05:51:46,034 INFO] Step 480000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49927/30445 tok/s;  29368 sec
[2020-02-03 05:51:46,036 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.valid.0.pt
[2020-02-03 05:51:46,199 INFO] number of examples: 30000
[2020-02-03 05:52:16,261 INFO] Validation perplexity: 1.03108
[2020-02-03 05:52:16,261 INFO] Validation accuracy: 99.5273
[2020-02-03 05:52:16,263 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_480000.pt
[2020-02-03 05:57:32,346 INFO] Step 481000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 45501/27748 tok/s;  29714 sec
[2020-02-03 06:02:47,573 INFO] Step 482000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49970/30469 tok/s;  30029 sec
[2020-02-03 06:04:20,313 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 06:04:35,107 INFO] number of examples: 818070
[2020-02-03 06:08:21,000 INFO] Step 483000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 47239/28850 tok/s;  30363 sec
[2020-02-03 06:13:36,274 INFO] Step 484000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49977/30368 tok/s;  30678 sec
[2020-02-03 06:18:51,979 INFO] Step 485000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49890/30565 tok/s;  30994 sec
[2020-02-03 06:23:17,551 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 06:23:28,853 INFO] number of examples: 818070
[2020-02-03 06:24:20,819 INFO] Step 486000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 47905/29147 tok/s;  31322 sec
[2020-02-03 06:29:36,736 INFO] Step 487000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49874/30485 tok/s;  31638 sec
[2020-02-03 06:34:52,197 INFO] Step 488000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 49942/30435 tok/s;  31954 sec
[2020-02-03 06:40:07,538 INFO] Step 489000/500000; acc:  99.89; ppl:  1.00; xent: 0.00; lr: 0.00018; 49949/30479 tok/s;  32269 sec
[2020-02-03 06:42:11,619 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 06:42:25,226 INFO] number of examples: 818070
[2020-02-03 06:45:39,686 INFO] Step 490000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 47424/28859 tok/s;  32601 sec
[2020-02-03 06:45:39,687 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.valid.0.pt
[2020-02-03 06:45:39,848 INFO] number of examples: 30000
[2020-02-03 06:46:09,854 INFO] Validation perplexity: 1.03116
[2020-02-03 06:46:09,855 INFO] Validation accuracy: 99.5313
[2020-02-03 06:46:09,857 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_490000.pt
[2020-02-03 06:51:25,540 INFO] Step 491000/500000; acc:  99.89; ppl:  1.00; xent: 0.00; lr: 0.00018; 45559/27749 tok/s;  32947 sec
[2020-02-03 06:56:40,620 INFO] Step 492000/500000; acc:  99.89; ppl:  1.00; xent: 0.00; lr: 0.00018; 49996/30565 tok/s;  33262 sec
[2020-02-03 07:01:38,137 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 07:01:56,037 INFO] number of examples: 818070
[2020-02-03 07:02:17,114 INFO] Step 493000/500000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00018; 46808/28529 tok/s;  33599 sec
[2020-02-03 07:07:32,907 INFO] Step 494000/500000; acc:  99.89; ppl:  1.00; xent: 0.00; lr: 0.00018; 49891/30414 tok/s;  33914 sec
[2020-02-03 07:12:47,837 INFO] Step 495000/500000; acc:  99.89; ppl:  1.00; xent: 0.00; lr: 0.00018; 50032/30565 tok/s;  34229 sec
[2020-02-03 07:18:03,112 INFO] Step 496000/500000; acc:  99.89; ppl:  1.00; xent: 0.00; lr: 0.00018; 49964/30474 tok/s;  34545 sec
[2020-02-03 07:20:38,634 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.train.0.pt
[2020-02-03 07:20:50,143 INFO] number of examples: 818070
[2020-02-03 07:23:32,960 INFO] Step 497000/500000; acc:  99.89; ppl:  1.00; xent: 0.00; lr: 0.00018; 47748/29101 tok/s;  34875 sec
[2020-02-03 07:28:48,186 INFO] Step 498000/500000; acc:  99.89; ppl:  1.00; xent: 0.00; lr: 0.00018; 49980/30451 tok/s;  35190 sec
[2020-02-03 07:34:03,956 INFO] Step 499000/500000; acc:  99.89; ppl:  1.00; xent: 0.00; lr: 0.00018; 49893/30467 tok/s;  35506 sec
[2020-02-03 07:39:19,391 INFO] Step 500000/500000; acc:  99.89; ppl:  1.00; xent: 0.00; lr: 0.00018; 49935/30475 tok/s;  35821 sec
[2020-02-03 07:39:19,392 INFO] Loading dataset from /home/dpk25/MolecularTransformer2/data/data/MIT_mixed_augm/MIT_mixed_augm.valid.0.pt
[2020-02-03 07:39:19,555 INFO] number of examples: 30000
[2020-02-03 07:39:49,554 INFO] Validation perplexity: 1.03178
[2020-02-03 07:39:49,555 INFO] Validation accuracy: 99.533
[2020-02-03 07:39:49,557 INFO] Saving checkpoint /home/dpk25/rds/hpc-work/MolecularTransformer2_models/checkpoints/MIT_mixed_augm_model_step_500000.pt
